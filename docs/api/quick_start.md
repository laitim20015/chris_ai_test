# æ™ºèƒ½æ–‡æª”è½‰æ›ç³»çµ± - å¿«é€Ÿé–‹å§‹æŒ‡å—
## Quick Start Guide

**ç‰ˆæœ¬**ï¼šv1.2  
**å‰µå»ºæ—¥æœŸ**ï¼š2025å¹´8æœˆ10æ—¥

---

## ğŸ“‹ ç›®éŒ„

1. [ç³»çµ±è¦æ±‚](#ç³»çµ±è¦æ±‚)
2. [å®‰è£èˆ‡é…ç½®](#å®‰è£èˆ‡é…ç½®)
3. [åŸºæœ¬ä½¿ç”¨](#åŸºæœ¬ä½¿ç”¨)
4. [APIæ¥å£](#apiæ¥å£)
5. [é€²éšé…ç½®](#é€²éšé…ç½®)
6. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## ğŸ”§ ç³»çµ±è¦æ±‚

### åŸºæœ¬è¦æ±‚
- **Python**: >= 3.9 (æ¨è–¦ 3.11)
- **å…§å­˜**: >= 4GB (æ¨è–¦ 8GB+)
- **å­˜å„²**: >= 2GB å¯ç”¨ç©ºé–“
- **æ“ä½œç³»çµ±**: Windows 10/11, macOS 10.15+, Ubuntu 18.04+

### å¯é¸è¦æ±‚ï¼ˆæå‡æ€§èƒ½ï¼‰
- **GPU**: NVIDIA GPU (æ”¯æ´CUDA) - èªç¾©åˆ†æåŠ é€Ÿ
- **Redis**: ç”¨æ–¼åˆ†æ•£å¼é™æµå’Œç·©å­˜
- **é›²ç«¯å­˜å„²**: Azure Blob Storage / AWS S3 / Google Cloud Storage

---

## ğŸš€ å®‰è£èˆ‡é…ç½®

### 1. å…‹éš†å°ˆæ¡ˆ

```bash
git clone https://github.com/your-org/AP_Project_RAG.git
cd AP_Project_RAG
```

### 2. å‰µå»ºè™›æ“¬ç’°å¢ƒ

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. å®‰è£ä¾è³´

```bash
pip install -r requirements.txt
```

### 4. ç’°å¢ƒé…ç½®

è¤‡è£½ç’°å¢ƒè®Šæ•¸ç¯„æœ¬ä¸¦é…ç½®ï¼š

```bash
cp .env.example .env
```

ç·¨è¼¯ `.env` æ–‡ä»¶ï¼š

```env
# åŸºæœ¬é…ç½®
APP_DEBUG=true
APP_LOG_LEVEL=INFO

# æ–‡ä»¶è™•ç†é…ç½®
MAX_FILE_SIZE_MB=100
SUPPORTED_FORMATS=pdf,docx,pptx

# Azure OpenAIé…ç½®ï¼ˆå¯é¸ï¼‰
AZURE_OPENAI_ENDPOINT=your-endpoint
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment

# å­˜å„²é…ç½®ï¼ˆå¯é¸ï¼‰
STORAGE_TYPE=local  # local, azure, aws, gcs
AZURE_STORAGE_CONNECTION_STRING=your-connection-string

# é™æµé…ç½®
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=60
```

---

## ğŸ’» åŸºæœ¬ä½¿ç”¨

### 1. å‘½ä»¤è¡Œè™•ç†å–®å€‹æ–‡æª”

```bash
python -m src.main process-document tests/fixtures/documents/sample.pdf
```

### 2. Python APIä½¿ç”¨

```python
import asyncio
from pathlib import Path
from src.main import DocumentProcessor

async def main():
    # åˆå§‹åŒ–è™•ç†å™¨
    processor = DocumentProcessor()
    
    # è™•ç†æ–‡æª”
    result = await processor.process_document("path/to/document.pdf")
    
    # ç²å–çµæœ
    markdown_content = result["markdown_content"]
    associations = result["associations"] 
    metadata = result["metadata"]
    
    print(f"ç”Ÿæˆäº† {len(associations)} å€‹åœ–æ–‡é—œè¯")
    print(f"æ–‡æª”åŒ…å« {len(metadata['text_blocks'])} å€‹æ–‡æœ¬å¡Š")
    
    # ä¿å­˜çµæœ
    with open("output.md", "w", encoding="utf-8") as f:
        f.write(markdown_content)

# é‹è¡Œ
asyncio.run(main())
```

### 3. æ‰¹é‡è™•ç†

```python
import asyncio
from pathlib import Path
from src.main import DocumentProcessor

async def batch_process():
    processor = DocumentProcessor()
    input_dir = Path("data/input/documents")
    output_dir = Path("data/output/markdown")
    
    for file_path in input_dir.glob("*.pdf"):
        print(f"è™•ç†æ–‡æª”: {file_path.name}")
        
        try:
            result = await processor.process_document(file_path)
            
            # ä¿å­˜Markdown
            output_file = output_dir / f"{file_path.stem}.md"
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(result["markdown_content"])
                
            print(f"âœ… å®Œæˆ: {output_file}")
            
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}")

asyncio.run(batch_process())
```

---

## ğŸŒ APIæ¥å£

### 1. å•Ÿå‹•APIæœå‹™å™¨

```bash
python -m src.api.main
```

æˆ–ä½¿ç”¨uvicornï¼š

```bash
uvicorn src.api.app:app --reload --host 0.0.0.0 --port 8000
```

### 2. ä¸Šå‚³æ–‡æª”

```bash
curl -X POST "http://localhost:8000/upload" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@sample.pdf"
```

éŸ¿æ‡‰ï¼š
```json
{
  "status": "success",
  "file_id": "doc_20250810_001",
  "filename": "sample.pdf",
  "size": 1024000
}
```

### 3. è™•ç†æ–‡æª”

```bash
curl -X POST "http://localhost:8000/process" \
  -H "Content-Type: application/json" \
  -d '{
    "file_id": "doc_20250810_001",
    "options": {
      "include_associations": true,
      "template": "enhanced"
    }
  }'
```

éŸ¿æ‡‰ï¼š
```json
{
  "status": "success",
  "processing_id": "proc_20250810_001",
  "estimated_time": 30
}
```

### 4. æŸ¥è©¢è™•ç†ç‹€æ…‹

```bash
curl "http://localhost:8000/status/proc_20250810_001"
```

éŸ¿æ‡‰ï¼š
```json
{
  "status": "completed",
  "progress": 100,
  "result": {
    "markdown_url": "/download/markdown/proc_20250810_001.md",
    "associations_count": 15,
    "processing_time": 25.6
  }
}
```

### 5. ä¸‹è¼‰çµæœ

```bash
# ä¸‹è¼‰Markdown
curl "http://localhost:8000/download/markdown/proc_20250810_001.md" -o result.md

# ä¸‹è¼‰é—œè¯æ•¸æ“š
curl "http://localhost:8000/download/associations/proc_20250810_001.json" -o associations.json
```

---

## âš™ï¸ é€²éšé…ç½®

### 1. é—œè¯ç®—æ³•èª¿å„ª

```python
from src.association import OptimizationConfig, create_balanced_config

# ä½¿ç”¨é è¨­é…ç½®
config = create_balanced_config()

# è‡ªå®šç¾©é…ç½®
custom_config = OptimizationConfig(
    min_score_threshold=0.5,        # æé«˜é–¾å€¼ï¼Œæ¸›å°‘ä½è³ªé‡é—œè¯
    max_associations_per_image=3,   # é™åˆ¶æ¯åœ–é—œè¯æ•¸
    caption_boost_factor=1.3,       # å¢å¼·Captionæ¬Šé‡
    prioritize_quality=True         # å„ªå…ˆä¿ç•™é«˜è³ªé‡é—œè¯
)
```

### 2. æ€§èƒ½ç›£æ§

```python
from src.utils.performance_benchmarks import get_profiler

# ç²å–æ€§èƒ½åˆ†æå™¨
profiler = get_profiler()

# å‰µå»ºæ¸¬è©¦å¥—ä»¶
suite = profiler.create_benchmark_suite(
    "production_benchmark",
    "ç”Ÿç”¢ç’°å¢ƒæ€§èƒ½åŸºæº–æ¸¬è©¦"
)

# åŸºæº–æ¸¬è©¦
results = profiler.benchmark_function(
    processor.process_document,
    args=("sample.pdf",),
    iterations=5
)

# ç”Ÿæˆå ±å‘Š
report = profiler.generate_report("production_benchmark")
print(f"å¹³å‡è™•ç†æ™‚é–“: {report['performance_stats']['execution_time']['avg']:.2f}s")
```

### 3. éŒ¯èª¤è™•ç†é…ç½®

```python
from src.utils.error_handling import get_error_handler, ErrorCategory, ErrorSeverity

# ç²å–éŒ¯èª¤è™•ç†å™¨
error_handler = get_error_handler()

# è‡ªå®šç¾©éŒ¯èª¤è™•ç†
try:
    result = await processor.process_document("problematic.pdf")
except Exception as e:
    error_info = error_handler.handle_error(
        e,
        category=ErrorCategory.PARSING,
        severity=ErrorSeverity.HIGH,
        context={"file": "problematic.pdf", "user": "admin"}
    )
    
    # ç²å–éŒ¯èª¤çµ±è¨ˆ
    stats = error_handler.get_error_statistics()
    print(f"ç¸½éŒ¯èª¤æ•¸: {stats['total_errors']}")
```

### 4. é›²ç«¯å­˜å„²é…ç½®

```python
# Azure Blob Storage
storage_config = {
    "type": "azure",
    "connection_string": "your-connection-string",
    "container_name": "documents"
}

# AWS S3
storage_config = {
    "type": "aws",
    "access_key": "your-access-key",
    "secret_key": "your-secret-key",
    "bucket_name": "documents",
    "region": "us-east-1"
}

# åˆå§‹åŒ–å¸¶å­˜å„²çš„è™•ç†å™¨
processor = DocumentProcessor(storage_config=storage_config)
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. å…§å­˜ä¸è¶³éŒ¯èª¤

**éŒ¯èª¤**: `MemoryError: Unable to allocate memory`

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# å•Ÿç”¨åˆ†å¡Šè™•ç†
processor = DocumentProcessor(
    chunk_size=1000,  # æ¸›å°å¡Šå¤§å°
    max_memory_usage="2GB"  # é™åˆ¶å…§å­˜ä½¿ç”¨
)
```

#### 2. PDFè§£æå¤±æ•—

**éŒ¯èª¤**: `PDFParsingError: Cannot parse PDF`

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# æª¢æŸ¥PDFè§£æå™¨å„ªå…ˆç´š
from src.parsers import get_parser_info
print(get_parser_info())

# å¼·åˆ¶ä½¿ç”¨ç‰¹å®šè§£æå™¨
result = await processor.process_document(
    "problematic.pdf",
    parser_preference=["pymupdf4llm", "unstructured"]
)
```

#### 3. æ¨¡å‹åŠ è¼‰å¤±æ•—

**éŒ¯èª¤**: `ModelNotFoundError: sentence-transformers model not found`

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æ‰‹å‹•ä¸‹è¼‰æ¨¡å‹
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"

# æˆ–ä½¿ç”¨é›¢ç·šæ¨¡å¼
export TRANSFORMERS_OFFLINE=1
```

#### 4. APIé™æµå•é¡Œ

**éŒ¯èª¤**: `429 Too Many Requests`

**è§£æ±ºæ–¹æ¡ˆ**:
```env
# èª¿æ•´é™æµé…ç½®
RATE_LIMIT_REQUESTS_PER_MINUTE=120
RATE_LIMIT_REQUESTS_PER_HOUR=2000

# æˆ–ç¦ç”¨é™æµï¼ˆåƒ…é–‹ç™¼ç’°å¢ƒï¼‰
RATE_LIMIT_ENABLED=false
```

### æ—¥èªŒèª¿è©¦

å•Ÿç”¨è©³ç´°æ—¥èªŒï¼š

```python
import logging
from src.config.logging_config import setup_logging

# è¨­ç½®èª¿è©¦ç´šåˆ¥
setup_logging(level=logging.DEBUG)

# æŸ¥çœ‹ç‰¹å®šçµ„ä»¶æ—¥èªŒ
logger = logging.getLogger("association_analyzer")
logger.setLevel(logging.DEBUG)
```

### æ€§èƒ½èª¿å„ª

```python
# æª¢æŸ¥ç³»çµ±è³‡æº
import psutil
print(f"CPUæ ¸å¿ƒæ•¸: {psutil.cpu_count()}")
print(f"å¯ç”¨å…§å­˜: {psutil.virtual_memory().available / 1024**3:.1f}GB")

# èª¿æ•´ä¸¦ç™¼é…ç½®
processor = DocumentProcessor(
    max_workers=psutil.cpu_count() // 2,  # ä½¿ç”¨ä¸€åŠCPUæ ¸å¿ƒ
    enable_gpu=True,  # å¦‚æœæœ‰GPU
    cache_embeddings=True  # å•Ÿç”¨åµŒå…¥ç·©å­˜
)
```

---

## ğŸ“š é€²éšä¸»é¡Œ

### 1. è‡ªå®šç¾©è§£æå™¨

```python
from src.parsers.base import BaseParser
from src.parsers import register_parser

class CustomParser(BaseParser):
    def parse(self, file_path: str) -> ParsedContent:
        # å¯¦ç¾è‡ªå®šç¾©è§£æé‚è¼¯
        pass

# è¨»å†Šè‡ªå®šç¾©è§£æå™¨
register_parser("custom", CustomParser, priority=1)
```

### 2. çŸ¥è­˜åº«é›†æˆ

```python
from src.knowledge_base import KnowledgeBaseFactory

# åˆå§‹åŒ–çŸ¥è­˜åº«é©é…å™¨
factory = KnowledgeBaseFactory()
adapter = factory.get_adapter("azure_ai_search")

# é…ç½®é€£æ¥
await adapter.initialize({
    "endpoint": "your-search-endpoint",
    "api_key": "your-api-key",
    "index_name": "documents"
})

# ç´¢å¼•æ–‡æª”
documents = [create_document_from_markdown(markdown_content, "source.pdf")]
await adapter.index_documents(documents, "documents")
```

### 3. è‡ªå®šç¾©Markdownæ¨¡æ¿

å‰µå»ºè‡ªå®šç¾©æ¨¡æ¿ `templates/custom.md.j2`ï¼š

```jinja2
# {{ title }}

{{ description }}

## æ–‡æª”å…§å®¹

{% for block in text_blocks %}
### {{ block.heading or "æ®µè½ " ~ loop.index }}

{{ block.content }}

{% if block.associated_images %}
**ç›¸é—œåœ–ç‰‡:**
{% for image in block.associated_images %}
- ![{{ image.alt_text }}]({{ image.url }}) (é—œè¯åº¦: {{ "%.2f" | format(image.score) }})
{% endfor %}
{% endif %}

{% endfor %}

## åœ–ç‰‡ç¸½è¦½

{% for image in images %}
![{{ image.alt_text }}]({{ image.url }})
{% endfor %}

---
*ç”±æ™ºèƒ½æ–‡æª”è½‰æ›ç³»çµ±ç”Ÿæˆæ–¼ {{ generation_time }}*
```

ä½¿ç”¨è‡ªå®šç¾©æ¨¡æ¿ï¼š

```python
result = await processor.process_document(
    "document.pdf",
    template_name="custom.md.j2"
)
```

---

## ğŸ“ æŠ€è¡“æ”¯æ´

### æ–‡æª”è³‡æº
- **æŠ€è¡“è¦æ ¼**: `docs/technical_specs/`
- **APIæ–‡æª”**: `docs/api/`
- **é–‹ç™¼è€…æŒ‡å—**: `docs/developer_guide/`

### ç¤¾ç¾¤æ”¯æ´
- **GitHub Issues**: [å°ˆæ¡ˆIssues](https://github.com/your-org/AP_Project_RAG/issues)
- **è¨è«–å€**: [GitHub Discussions](https://github.com/your-org/AP_Project_RAG/discussions)

### è¯ç¹«æ–¹å¼
- **æŠ€è¡“å•é¡Œ**: tech-support@your-org.com
- **åŠŸèƒ½å»ºè­°**: feature-requests@your-org.com

---

**æœ€å¾Œæ›´æ–°**: 2025å¹´8æœˆ10æ—¥  
**ç‰ˆæœ¬**: v1.2  
**ç¶­è­·åœ˜éšŠ**: æ™ºèƒ½æ–‡æª”è½‰æ›ç³»çµ±é–‹ç™¼åœ˜éšŠ
