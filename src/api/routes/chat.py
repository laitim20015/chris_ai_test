"""
AIå°è©±APIç«¯é»

æä¾›åŸºæ–¼Azure OpenAIçš„èŠå¤©åŠŸèƒ½ï¼Œæ”¯æŒRAGå¢å¼·å’Œæµå¼éŸ¿æ‡‰ã€‚
"""

from typing import List, Optional
from fastapi import APIRouter, HTTPException, Depends, Request
from fastapi.responses import StreamingResponse
import json
from datetime import datetime

from ...services.azure_openai_service import get_azure_openai_service, AzureOpenAIService, ChatMessage
from ...services.document_service import get_document_service, DocumentService
from ..models.request_models import ChatRequest, ChatMessage as ApiChatMessage
from ..models.response_models import ChatResponse, ChatUsage, ErrorResponse
from ..middleware.auth import is_authenticated
from loguru import logger


router = APIRouter()
chat_logger = logger.bind(module="api.chat")


def get_authenticated_azure_openai_service(request: Request) -> AzureOpenAIService:
    """ä¾è³´æ³¨å…¥ï¼šç²å–å·²èªè­‰çš„Azure OpenAIæœå‹™"""
    if not is_authenticated(request):
        raise HTTPException(status_code=401, detail="æœªèªè­‰çš„è«‹æ±‚")
    return get_azure_openai_service()


def get_authenticated_document_service(request: Request) -> DocumentService:
    """ä¾è³´æ³¨å…¥ï¼šç²å–å·²èªè­‰çš„æ–‡æª”æœå‹™"""
    if not is_authenticated(request):
        raise HTTPException(status_code=401, detail="æœªèªè­‰çš„è«‹æ±‚")
    return get_document_service()


@router.post("/chat", response_model=ChatResponse, tags=["AIå°è©±"])
async def chat_completion(
    chat_request: ChatRequest,
    azure_service: AzureOpenAIService = Depends(get_authenticated_azure_openai_service),
    document_service: DocumentService = Depends(get_authenticated_document_service)
):
    """
    AIèŠå¤©å®Œæˆ
    
    æä¾›åŸºæ–¼Azure OpenAIçš„æ™ºèƒ½å°è©±åŠŸèƒ½ï¼Œæ”¯æŒRAGæ–‡æª”ä¸Šä¸‹æ–‡å¢å¼·ã€‚
    
    - **messages**: å°è©±æ­·å²æ¶ˆæ¯åˆ—è¡¨
    - **model**: ä½¿ç”¨çš„GPTæ¨¡å‹ï¼ˆgpt-4, gpt-35-turboç­‰ï¼‰
    - **temperature**: æº«åº¦åƒæ•¸ï¼Œæ§åˆ¶å›å¾©çš„å‰µé€ æ€§
    - **use_document_context**: æ˜¯å¦ä½¿ç”¨æ–‡æª”ä¸Šä¸‹æ–‡é€²è¡ŒRAGå¢å¼·
    - **document_ids**: ç›¸é—œæ–‡æª”IDåˆ—è¡¨ï¼ˆRAGæ¨¡å¼ä¸‹ï¼‰
    - **include_images**: æ˜¯å¦åœ¨å›å¾©ä¸­åŒ…å«ç›¸é—œåœ–ç‰‡ä¿¡æ¯
    """
    try:
        chat_logger.info(f"ğŸ’¬ æ”¶åˆ°èŠå¤©è«‹æ±‚ - æ¨¡å‹: {chat_request.model}, æ¶ˆæ¯æ•¸: {len(chat_request.messages)}")
        
        # è½‰æ›æ¶ˆæ¯æ ¼å¼
        messages = [
            ChatMessage(role=msg.role, content=msg.content)
            for msg in chat_request.messages
        ]
        
        # RAGå¢å¼·ï¼šæ·»åŠ æ–‡æª”ä¸Šä¸‹æ–‡
        if chat_request.use_document_context and chat_request.document_ids:
            enhanced_messages = await _enhance_with_document_context(
                messages, 
                chat_request.document_ids,
                chat_request.include_images,
                document_service
            )
            messages = enhanced_messages
        
        # èª¿ç”¨Azure OpenAI
        response = await azure_service.chat_completion(
            messages=messages,
            model=chat_request.model,
            temperature=chat_request.temperature,
            max_tokens=chat_request.max_tokens
        )
        
        # æ§‹å»ºéŸ¿æ‡‰
        chat_response = ChatResponse(
            id=response["id"],
            model=response["model"],
            message=response["message"],
            usage=ChatUsage(
                prompt_tokens=response["usage"].prompt_tokens,
                completion_tokens=response["usage"].completion_tokens,
                total_tokens=response["usage"].total_tokens
            ),
            context_used=chat_request.use_document_context,
            source_documents=chat_request.document_ids if chat_request.use_document_context else None,
            related_images=[] if chat_request.include_images else None,  # TODO: å¯¦ç¾åœ–ç‰‡é—œè¯
            created_at=response["created_at"],
            processing_time=response["processing_time"]
        )
        
        chat_logger.info(f"âœ… èŠå¤©è«‹æ±‚å®Œæˆ - Tokenä½¿ç”¨: {response['usage'].total_tokens}")
        return chat_response
        
    except Exception as e:
        chat_logger.error(f"âŒ èŠå¤©è«‹æ±‚å¤±æ•—: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"èŠå¤©è«‹æ±‚è™•ç†å¤±æ•—: {str(e)}"
        )


@router.post("/chat/stream", tags=["AIå°è©±"])
async def chat_completion_stream(
    chat_request: ChatRequest,
    azure_service: AzureOpenAIService = Depends(get_authenticated_azure_openai_service),
    document_service: DocumentService = Depends(get_authenticated_document_service)
):
    """
    æµå¼AIèŠå¤©å®Œæˆ
    
    æä¾›å¯¦æ™‚æµå¼éŸ¿æ‡‰çš„AIå°è©±åŠŸèƒ½ï¼Œé©åˆé•·å›å¾©å’Œå¯¦æ™‚äº¤äº’ã€‚
    
    è¿”å›æ ¼å¼ï¼šServer-Sent Events (SSE)
    """
    try:
        chat_logger.info(f"ğŸŒŠ æ”¶åˆ°æµå¼èŠå¤©è«‹æ±‚ - æ¨¡å‹: {chat_request.model}")
        
        # è½‰æ›æ¶ˆæ¯æ ¼å¼
        messages = [
            ChatMessage(role=msg.role, content=msg.content)
            for msg in chat_request.messages
        ]
        
        # RAGå¢å¼·ï¼šæ·»åŠ æ–‡æª”ä¸Šä¸‹æ–‡
        if chat_request.use_document_context and chat_request.document_ids:
            enhanced_messages = await _enhance_with_document_context(
                messages, 
                chat_request.document_ids,
                chat_request.include_images,
                document_service
            )
            messages = enhanced_messages
        
        # æµå¼éŸ¿æ‡‰ç”Ÿæˆå™¨
        async def generate_stream():
            try:
                async for chunk in azure_service.chat_completion_stream(
                    messages=messages,
                    model=chat_request.model,
                    temperature=chat_request.temperature,
                    max_tokens=chat_request.max_tokens
                ):
                    # æ§‹å»ºSSEæ ¼å¼
                    sse_data = {
                        "id": chunk["id"],
                        "content": chunk["content"],
                        "finish_reason": chunk["finish_reason"]
                    }
                    
                    yield f"data: {json.dumps(sse_data, ensure_ascii=False)}\n\n"
                    
                    # å¦‚æœå°è©±çµæŸ
                    if chunk["finish_reason"]:
                        break
                
                # ç™¼é€çµæŸæ¨™è¨˜
                yield "data: [DONE]\n\n"
                
            except Exception as e:
                error_data = {"error": str(e)}
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
        
        return StreamingResponse(
            generate_stream(),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Content-Type-Options": "nosniff"
            }
        )
        
    except Exception as e:
        chat_logger.error(f"âŒ æµå¼èŠå¤©è«‹æ±‚å¤±æ•—: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"æµå¼èŠå¤©è«‹æ±‚è™•ç†å¤±æ•—: {str(e)}"
        )


@router.get("/chat/health", tags=["AIå°è©±"])
async def chat_health_check(
    azure_service: AzureOpenAIService = Depends(get_authenticated_azure_openai_service)
):
    """
    èŠå¤©æœå‹™å¥åº·æª¢æŸ¥
    
    æª¢æŸ¥Azure OpenAIæœå‹™çš„é€£æ¥ç‹€æ…‹å’Œå¯ç”¨æ€§ã€‚
    """
    try:
        health_status = await azure_service.health_check()
        
        if health_status["status"] == "healthy":
            return {
                "status": "healthy",
                "service": "Azure OpenAI Chat",
                "endpoint": health_status["endpoint"],
                "models": {
                    "chat": health_status["chat_model"],
                    "embedding": health_status["embedding_model"]
                },
                "test_response_time": health_status["test_response_time"],
                "timestamp": datetime.utcnow()
            }
        else:
            raise HTTPException(
                status_code=503,
                detail=f"Azure OpenAIæœå‹™ä¸å¥åº·: {health_status.get('error', 'æœªçŸ¥éŒ¯èª¤')}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        chat_logger.error(f"âŒ å¥åº·æª¢æŸ¥å¤±æ•—: {str(e)}")
        raise HTTPException(
            status_code=503,
            detail=f"å¥åº·æª¢æŸ¥å¤±æ•—: {str(e)}"
        )


async def _enhance_with_document_context(
    messages: List[ChatMessage],
    document_ids: List[str],
    include_images: bool,
    document_service: DocumentService
) -> List[ChatMessage]:
    """
    ä½¿ç”¨æ–‡æª”ä¸Šä¸‹æ–‡å¢å¼·æ¶ˆæ¯ï¼ˆRAGåŠŸèƒ½ï¼‰
    
    Args:
        messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
        document_ids: æ–‡æª”IDåˆ—è¡¨
        include_images: æ˜¯å¦åŒ…å«åœ–ç‰‡ä¿¡æ¯
        document_service: æ–‡æª”æœå‹™
        
    Returns:
        å¢å¼·å¾Œçš„æ¶ˆæ¯åˆ—è¡¨
    """
    try:
        # æ”¶é›†ç›¸é—œæ–‡æª”å…§å®¹
        context_parts = []
        
        for doc_id in document_ids:
            # æŸ¥æ‰¾å°æ‡‰çš„è™•ç†ä»»å‹™
            for task_id, task in document_service.tasks.items():
                if task.document_id == doc_id and task.markdown_content:
                    context_parts.append(f"## æ–‡æª”: {task.filename}\n\n{task.markdown_content}")
                    break
        
        if not context_parts:
            chat_logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ–‡æª”ä¸Šä¸‹æ–‡: {document_ids}")
            return messages
        
        # å‰µå»ºç³»çµ±æç¤ºï¼ŒåŒ…å«æ–‡æª”ä¸Šä¸‹æ–‡
        context_content = "\n\n".join(context_parts)
        system_message = ChatMessage(
            role="system",
            content=f"""ä½ æ˜¯ä¸€å€‹æ™ºèƒ½æ–‡æª”åŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯ç›¸é—œçš„æ–‡æª”å…§å®¹ï¼š

{context_content}

è«‹åŸºæ–¼é€™äº›æ–‡æª”å…§å®¹ä¾†å›ç­”ç”¨æˆ¶çš„å•é¡Œã€‚å¦‚æœå•é¡Œèˆ‡æ–‡æª”å…§å®¹ç›¸é—œï¼Œè«‹å¼•ç”¨å…·é«”çš„æ®µè½æˆ–åœ–è¡¨ã€‚å¦‚æœæ–‡æª”ä¸­æ²’æœ‰ç›¸é—œä¿¡æ¯ï¼Œè«‹æ˜ç¢ºèªªæ˜ã€‚"""
        )
        
        # å°‡ç³»çµ±æ¶ˆæ¯æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨é–‹é ­
        enhanced_messages = [system_message] + messages
        
        chat_logger.info(f"ğŸ“š RAGä¸Šä¸‹æ–‡å¢å¼·å®Œæˆ - æ–‡æª”æ•¸: {len(document_ids)}, ä¸Šä¸‹æ–‡é•·åº¦: {len(context_content)}å­—ç¬¦")
        
        return enhanced_messages
        
    except Exception as e:
        chat_logger.error(f"âŒ RAGä¸Šä¸‹æ–‡å¢å¼·å¤±æ•—: {str(e)}")
        # å¦‚æœå¢å¼·å¤±æ•—ï¼Œè¿”å›åŸå§‹æ¶ˆæ¯
        return messages
