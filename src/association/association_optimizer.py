"""
é—œè¯å„ªåŒ–å™¨
Association Optimizer

è§£æ±ºéåº¦é—œè¯å•é¡Œï¼Œæä¾›æ™ºèƒ½çš„é—œè¯å»é‡å’Œéæ¿¾æ©Ÿåˆ¶ã€‚
åŒ…å«å¤šç¨®å„ªåŒ–ç­–ç•¥ï¼š
1. åŸºæ–¼é–¾å€¼çš„éæ¿¾
2. æ¯å¼µåœ–ç‰‡çš„æœ€å¤§é—œè¯æ•¸é™åˆ¶
3. é—œè¯è³ªé‡è©•ä¼°
4. é‡è¤‡é—œè¯å»é‡
5. è·é›¢å’Œèªç¾©ç›¸ä¼¼åº¦èšé¡
"""

from typing import List, Dict, Any, Set, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import math
from collections import defaultdict

from src.config.logging_config import get_logger

logger = get_logger("association_optimizer")

class AssociationQuality(Enum):
    """é—œè¯è³ªé‡ç­‰ç´š"""
    EXCELLENT = "excellent"    # 0.8+
    GOOD = "good"             # 0.6-0.8
    FAIR = "fair"             # 0.4-0.6
    POOR = "poor"             # 0.2-0.4
    INVALID = "invalid"       # <0.2

@dataclass
class OptimizationConfig:
    """å„ªåŒ–é…ç½®"""
    # åŸºæœ¬é–¾å€¼
    min_score_threshold: float = 0.4           # æœ€ä½é—œè¯åˆ†æ•¸
    excellent_threshold: float = 0.8           # å„ªç§€é—œè¯åˆ†æ•¸
    good_threshold: float = 0.6                # è‰¯å¥½é—œè¯åˆ†æ•¸
    fair_threshold: float = 0.4                # ä¸€èˆ¬é—œè¯åˆ†æ•¸
    
    # æ•¸é‡é™åˆ¶
    max_associations_per_image: int = 5        # æ¯å¼µåœ–ç‰‡æœ€å¤§é—œè¯æ•¸
    max_total_associations: int = 100          # ç¸½æœ€å¤§é—œè¯æ•¸
    
    # Captionç‰¹æ®Šè™•ç†
    caption_boost_factor: float = 1.2          # Captionæª¢æ¸¬åŠ æˆä¿‚æ•¸
    caption_min_confidence: float = 0.5       # Captionæœ€ä½ç½®ä¿¡åº¦
    
    # å»é‡é…ç½®
    enable_deduplication: bool = True          # å•Ÿç”¨å»é‡
    similarity_threshold: float = 0.9          # ç›¸ä¼¼é—œè¯åˆä½µé–¾å€¼
    
    # è³ªé‡å„ªå…ˆ
    prioritize_quality: bool = True            # å„ªå…ˆä¿ç•™é«˜è³ªé‡é—œè¯
    quality_boost_factor: float = 1.1         # è³ªé‡åŠ æˆä¿‚æ•¸

class AssociationOptimizer:
    """é—œè¯å„ªåŒ–å™¨"""
    
    def __init__(self, config: OptimizationConfig = None):
        """
        åˆå§‹åŒ–å„ªåŒ–å™¨
        
        Args:
            config: å„ªåŒ–é…ç½®
        """
        self.config = config or OptimizationConfig()
        self.logger = logger
        
        self.logger.info("é—œè¯å„ªåŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def optimize_associations(self, 
                            associations: List[Dict[str, Any]],
                            images: List[Any] = None,
                            text_blocks: List[Any] = None) -> List[Dict[str, Any]]:
        """
        å„ªåŒ–é—œè¯åˆ—è¡¨
        
        Args:
            associations: åŸå§‹é—œè¯åˆ—è¡¨
            images: åœ–ç‰‡åˆ—è¡¨ï¼ˆå¯é¸ï¼Œç”¨æ–¼é¡å¤–é©—è­‰ï¼‰
            text_blocks: æ–‡æœ¬å¡Šåˆ—è¡¨ï¼ˆå¯é¸ï¼Œç”¨æ–¼é¡å¤–é©—è­‰ï¼‰
            
        Returns:
            å„ªåŒ–å¾Œçš„é—œè¯åˆ—è¡¨
        """
        self.logger.info(f"ğŸ”§ é–‹å§‹é—œè¯å„ªåŒ–ï¼ŒåŸå§‹é—œè¯æ•¸: {len(associations)}")
        
        if not associations:
            return []
        
        # æ­¥é©Ÿ1: åŸºæœ¬éæ¿¾
        filtered_associations = self._filter_by_threshold(associations)
        self.logger.info(f"ğŸ“Š é–¾å€¼éæ¿¾å¾Œ: {len(filtered_associations)} å€‹é—œè¯")
        
        # æ­¥é©Ÿ2: è³ªé‡è©•ä¼°å’Œåˆ†ç´š
        graded_associations = self._grade_associations(filtered_associations)
        self.logger.info(f"ğŸ“ˆ è³ªé‡è©•ä¼°å®Œæˆ")
        
        # æ­¥é©Ÿ3: Captionæª¢æ¸¬åŠ æˆ
        boosted_associations = self._apply_caption_boost(graded_associations)
        self.logger.info(f"ğŸ¯ CaptionåŠ æˆè™•ç†å®Œæˆ")
        
        # æ­¥é©Ÿ4: å»é‡è™•ç†
        if self.config.enable_deduplication:
            deduplicated_associations = self._deduplicate_associations(boosted_associations)
            self.logger.info(f"ğŸ”„ å»é‡è™•ç†å¾Œ: {len(deduplicated_associations)} å€‹é—œè¯")
        else:
            deduplicated_associations = boosted_associations
        
        # æ­¥é©Ÿ5: æŒ‰åœ–ç‰‡é™åˆ¶é—œè¯æ•¸
        limited_associations = self._limit_associations_per_image(deduplicated_associations)
        self.logger.info(f"ğŸšï¸ æ•¸é‡é™åˆ¶å¾Œ: {len(limited_associations)} å€‹é—œè¯")
        
        # æ­¥é©Ÿ6: ç¸½æ•¸æ§åˆ¶
        final_associations = self._limit_total_associations(limited_associations)
        self.logger.info(f"âœ… æœ€çµ‚å„ªåŒ–çµæœ: {len(final_associations)} å€‹é—œè¯")
        
        # çµ±è¨ˆå ±å‘Š
        self._generate_optimization_report(associations, final_associations)
        
        return final_associations
    
    def _filter_by_threshold(self, associations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åŸºæœ¬é–¾å€¼éæ¿¾"""
        filtered = []
        
        for assoc in associations:
            final_score = assoc.get("final_score", 0.0)
            
            if final_score >= self.config.min_score_threshold:
                filtered.append(assoc)
            else:
                self.logger.debug(f"éæ¿¾ä½åˆ†é—œè¯: {final_score:.3f}")
        
        return filtered
    
    def _grade_associations(self, associations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """é—œè¯è³ªé‡è©•ä¼°å’Œåˆ†ç´š"""
        graded = []
        
        for assoc in associations.copy():
            final_score = assoc.get("final_score", 0.0)
            
            # ç¢ºå®šè³ªé‡ç­‰ç´š
            if final_score >= self.config.excellent_threshold:
                quality = AssociationQuality.EXCELLENT
            elif final_score >= self.config.good_threshold:
                quality = AssociationQuality.GOOD
            elif final_score >= self.config.fair_threshold:
                quality = AssociationQuality.FAIR
            else:
                quality = AssociationQuality.POOR
            
            # æ·»åŠ è³ªé‡ä¿¡æ¯
            assoc["quality"] = quality.value
            assoc["quality_enum"] = quality
            
            # è³ªé‡åŠ æˆ
            if self.config.prioritize_quality and quality in [AssociationQuality.EXCELLENT, AssociationQuality.GOOD]:
                assoc["adjusted_score"] = final_score * self.config.quality_boost_factor
            else:
                assoc["adjusted_score"] = final_score
            
            graded.append(assoc)
        
        return graded
    
    def _apply_caption_boost(self, associations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Captionæª¢æ¸¬åŠ æˆè™•ç†"""
        boosted = []
        
        for assoc in associations.copy():
            caption_score = assoc.get("caption_score", 0.0)
            
            # Captionæª¢æ¸¬åŠ æˆ
            if caption_score >= self.config.caption_min_confidence:
                boost_factor = self.config.caption_boost_factor
                assoc["adjusted_score"] = assoc.get("adjusted_score", assoc["final_score"]) * boost_factor
                assoc["caption_boosted"] = True
                # åŒæ­¥æ›´æ–°é—œè¯é¡å‹ç‚ºcaptionï¼Œç¢ºä¿è¼¸å‡ºä¸€è‡´æ€§
                assoc["association_type"] = "caption"
                
                self.logger.debug(f"CaptionåŠ æˆ: {assoc['final_score']:.3f} -> {assoc['adjusted_score']:.3f}")
            else:
                assoc["caption_boosted"] = False
            
            boosted.append(assoc)
        
        return boosted
    
    def _deduplicate_associations(self, associations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """é—œè¯å»é‡è™•ç†"""
        if len(associations) <= 1:
            return associations
        
        # æŒ‰èª¿æ•´å¾Œåˆ†æ•¸æ’åº
        sorted_associations = sorted(associations, key=lambda x: x.get("adjusted_score", x["final_score"]), reverse=True)
        
        deduplicated = []
        used_combinations: Set[Tuple[str, str]] = set()
        
        for assoc in sorted_associations:
            text_id = assoc.get("text_block_id", "")
            image_id = assoc.get("image_id", "")
            
            combination = (text_id, image_id)
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçµ„åˆ
            if combination not in used_combinations:
                deduplicated.append(assoc)
                used_combinations.add(combination)
            else:
                self.logger.debug(f"å»é‡: é‡è¤‡çµ„åˆ {text_id} <-> {image_id}")
        
        return deduplicated
    
    def _limit_associations_per_image(self, associations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """é™åˆ¶æ¯å¼µåœ–ç‰‡çš„é—œè¯æ•¸"""
        # æŒ‰åœ–ç‰‡åˆ†çµ„
        image_groups = defaultdict(list)
        
        for assoc in associations:
            image_id = assoc.get("image_id", "")
            image_groups[image_id].append(assoc)
        
        limited = []
        
        for image_id, image_associations in image_groups.items():
            # æŒ‰èª¿æ•´å¾Œåˆ†æ•¸æ’åº
            sorted_assocs = sorted(
                image_associations, 
                key=lambda x: x.get("adjusted_score", x["final_score"]), 
                reverse=True
            )
            
            # é™åˆ¶æ•¸é‡
            kept_count = min(len(sorted_assocs), self.config.max_associations_per_image)
            kept_associations = sorted_assocs[:kept_count]
            
            limited.extend(kept_associations)
            
            if len(sorted_assocs) > kept_count:
                self.logger.debug(f"åœ–ç‰‡ {image_id} é—œè¯é™åˆ¶: {len(sorted_assocs)} -> {kept_count}")
        
        return limited
    
    def _limit_total_associations(self, associations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç¸½é—œè¯æ•¸æ§åˆ¶"""
        if len(associations) <= self.config.max_total_associations:
            return associations
        
        # æŒ‰èª¿æ•´å¾Œåˆ†æ•¸æ’åº
        sorted_associations = sorted(
            associations, 
            key=lambda x: x.get("adjusted_score", x["final_score"]), 
            reverse=True
        )
        
        limited = sorted_associations[:self.config.max_total_associations]
        
        self.logger.info(f"ç¸½æ•¸é™åˆ¶: {len(associations)} -> {len(limited)}")
        
        return limited
    
    def _generate_optimization_report(self, 
                                    original: List[Dict[str, Any]], 
                                    optimized: List[Dict[str, Any]]):
        """ç”Ÿæˆå„ªåŒ–å ±å‘Š"""
        original_count = len(original)
        optimized_count = len(optimized)
        reduction_rate = (original_count - optimized_count) / max(original_count, 1) * 100
        
        # è³ªé‡åˆ†å¸ƒçµ±è¨ˆ
        quality_stats = defaultdict(int)
        for assoc in optimized:
            quality = assoc.get("quality", "unknown")
            quality_stats[quality] += 1
        
        # Captionæª¢æ¸¬çµ±è¨ˆ
        caption_boosted = sum(1 for assoc in optimized if assoc.get("caption_boosted", False))
        
        self.logger.info("ğŸ“Š é—œè¯å„ªåŒ–å ±å‘Š:")
        self.logger.info(f"  ğŸ“‰ é—œè¯æ•¸è®ŠåŒ–: {original_count} -> {optimized_count}")
        self.logger.info(f"  ğŸ“ˆ å„ªåŒ–ç‡: {reduction_rate:.1f}%")
        self.logger.info(f"  ğŸ¯ CaptionåŠ æˆ: {caption_boosted}/{optimized_count}")
        self.logger.info(f"  ğŸ“ˆ è³ªé‡åˆ†å¸ƒ:")
        
        for quality, count in quality_stats.items():
            percentage = count / max(optimized_count, 1) * 100
            self.logger.info(f"    {quality}: {count} ({percentage:.1f}%)")
    
    def get_optimization_metrics(self, 
                                original: List[Dict[str, Any]], 
                                optimized: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç²å–å„ªåŒ–æŒ‡æ¨™"""
        if not original:
            return {"error": "æ²’æœ‰åŸå§‹é—œè¯æ•¸æ“š"}
        
        original_count = len(original)
        optimized_count = len(optimized)
        
        # åˆ†æ•¸çµ±è¨ˆ
        original_scores = [assoc.get("final_score", 0.0) for assoc in original]
        optimized_scores = [assoc.get("final_score", 0.0) for assoc in optimized]
        
        original_avg = sum(original_scores) / max(len(original_scores), 1)
        optimized_avg = sum(optimized_scores) / max(len(optimized_scores), 1)
        
        # è³ªé‡åˆ†å¸ƒ
        quality_distribution = defaultdict(int)
        for assoc in optimized:
            quality = assoc.get("quality", "unknown")
            quality_distribution[quality] += 1
        
        return {
            "original_count": original_count,
            "optimized_count": optimized_count,
            "reduction_count": original_count - optimized_count,
            "reduction_rate": (original_count - optimized_count) / max(original_count, 1) * 100,
            "original_avg_score": original_avg,
            "optimized_avg_score": optimized_avg,
            "quality_improvement": optimized_avg - original_avg,
            "quality_distribution": dict(quality_distribution),
            "caption_boosted_count": sum(1 for assoc in optimized if assoc.get("caption_boosted", False))
        }

# ä¾¿æ·å‡½æ•¸
def optimize_associations(associations: List[Dict[str, Any]], 
                         config: OptimizationConfig = None) -> List[Dict[str, Any]]:
    """
    å„ªåŒ–é—œè¯åˆ—è¡¨ï¼ˆä¾¿æ·å‡½æ•¸ï¼‰
    
    Args:
        associations: åŸå§‹é—œè¯åˆ—è¡¨
        config: å„ªåŒ–é…ç½®
        
    Returns:
        å„ªåŒ–å¾Œçš„é—œè¯åˆ—è¡¨
    """
    optimizer = AssociationOptimizer(config)
    return optimizer.optimize_associations(associations)

def create_strict_config() -> OptimizationConfig:
    """å‰µå»ºåš´æ ¼çš„å„ªåŒ–é…ç½®"""
    return OptimizationConfig(
        min_score_threshold=0.5,
        max_associations_per_image=3,
        max_total_associations=50,
        caption_min_confidence=0.6,
        prioritize_quality=True
    )

def create_balanced_config() -> OptimizationConfig:
    """å‰µå»ºå¹³è¡¡çš„å„ªåŒ–é…ç½®"""
    return OptimizationConfig(
        min_score_threshold=0.4,
        max_associations_per_image=5,
        max_total_associations=100,
        caption_min_confidence=0.5,
        prioritize_quality=True
    )

def create_lenient_config() -> OptimizationConfig:
    """å‰µå»ºå¯¬é¬†çš„å„ªåŒ–é…ç½®"""
    return OptimizationConfig(
        min_score_threshold=0.3,
        max_associations_per_image=8,
        max_total_associations=200,
        caption_min_confidence=0.4,
        prioritize_quality=False
    )
