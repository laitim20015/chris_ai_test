#!/usr/bin/env python3
"""
é—œè¯åˆ†æå°ˆé …æ¸¬è©¦è…³æœ¬
å°ˆé–€æ¸¬è©¦åœ–æ–‡é—œè¯åˆ†æåŠŸèƒ½ï¼Œç‰¹åˆ¥æ˜¯æ®µè½102é¡ä¼¼å•é¡Œçš„è¨ºæ–·

ä¸»è¦æ¸¬è©¦å…§å®¹ï¼š
1. Captionæª¢æ¸¬æº–ç¢ºæ€§ï¼ˆæè¿°æ€§æŒ‡ç¤ºè©ï¼‰
2. ç©ºé–“é—œä¿‚è¨ˆç®—èˆ‡å„ªå…ˆç´š
3. CandidateRankeræ™ºèƒ½æ’åº
4. AssociationOptimizeré¡å‹åŒæ­¥
5. å®Œæ•´é—œè¯æµç¨‹é©—è­‰

ä½¿ç”¨æ–¹å¼ï¼š
python test_association_analysis_focused.py
"""

import os
import sys
import logging
from typing import List, Dict, Any, Tuple
from pathlib import Path
import json
from datetime import datetime

# æ·»åŠ srcç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent / "src"))

from src.parsers.base import TextBlock, ImageContent, ContentType, ImageFormat
from src.association.allen_logic import BoundingBox
from src.association.caption_detector import CaptionDetector
from src.association.spatial_analyzer import SpatialAnalyzer
from src.association.semantic_analyzer import SemanticAnalyzer
from src.association.association_scorer import AssociationScorer
from src.association.association_optimizer import AssociationOptimizer
from src.association.candidate_ranker import CandidateRanker
from src.config.settings import Settings

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AssociationAnalysisTest:
    """é—œè¯åˆ†æå°ˆé …æ¸¬è©¦é¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¸¬è©¦çµ„ä»¶"""
        self.settings = Settings()
        self.caption_detector = CaptionDetector()
        self.spatial_analyzer = SpatialAnalyzer()
        self.semantic_analyzer = SemanticAnalyzer()
        self.association_scorer = AssociationScorer()
        self.association_optimizer = AssociationOptimizer()
        self.candidate_ranker = CandidateRanker(
            caption_detector=self.caption_detector,
            semantic_analyzer=self.semantic_analyzer
        )
        
        # æ¸¬è©¦çµæœæ”¶é›†
        self.test_results = {
            'timestamp': datetime.now().isoformat(),
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'test_details': []
        }
        
        logger.info("é—œè¯åˆ†ææ¸¬è©¦çµ„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    def create_test_scenario_paragraph_102(self) -> Tuple[List[TextBlock], List[ImageContent]]:
        """å‰µå»ºæ®µè½102é¡ä¼¼çš„æ¸¬è©¦å ´æ™¯"""
        
        # æ¨¡æ“¬æ®µè½102ï¼šæè¿°æ€§CaptionæŒ‡ç¤ºè©
        text_blocks = [
            TextBlock(
                id="p102",
                content="ä¸‹åˆ—åœ–è¡¨æè¿°äº†å·¥ä½œå°å•†å‹™åç‰‡é€²è¡Œæ‹¼ç‰ˆçš„æ–¹å¼ã€‚",
                content_type=ContentType.PARAGRAPH,
                page_number=1,
                bbox=BoundingBox(x=100, y=200, width=400, height=30)
            ),
            TextBlock(
                id="p103",
                content="1 5 æ¬„",
                content_type=ContentType.PARAGRAPH,
                page_number=1,
                bbox=BoundingBox(x=150, y=400, width=50, height=20)
            ),
            TextBlock(
                id="p104", 
                content="2 5 åˆ—",
                content_type=ContentType.PARAGRAPH,
                page_number=1,
                bbox=BoundingBox(x=150, y=430, width=50, height=20)
            ),
            TextBlock(
                id="p116",
                content="â€¢ 11 x 17 é‡ç£…ç´™ï¼Œå¦‚å¡ç‰‡ç´™å¼µ",
                content_type=ContentType.LIST,
                page_number=1,
                bbox=BoundingBox(x=120, y=650, width=280, height=20)
            ),
            TextBlock(
                id="p120",
                content="4 é¸æ“‡è¯åˆæ‹¼ç‰ˆï¼Œç„¶å¾Œé¸æ“‡é‡è¤‡ã€‚",
                content_type=ContentType.PARAGRAPH,
                page_number=1,
                bbox=BoundingBox(x=120, y=720, width=300, height=20)
            )
        ]
        
        # ç›®æ¨™åœ–ç‰‡ä½ç½®ï¼ˆæ‡‰è©²é—œè¯åˆ°p102ï¼‰
        images = [
            ImageContent(
                id="img_001",
                filename="workflows_sample_p011_img001.png",
                format=ImageFormat.PNG,
                data=b"fake_image_data",
                page_number=1,
                bbox=BoundingBox(x=100, y=250, width=400, height=130),  # åœ¨p102ä¸‹æ–¹
                alt_text="å•†å‹™åç‰‡æ‹¼ç‰ˆå¸ƒå±€åœ–è¡¨"
            )
        ]
        
        return text_blocks, images
    
    def test_caption_detection_descriptive_words(self) -> Dict[str, Any]:
        """æ¸¬è©¦æè¿°æ€§æŒ‡ç¤ºè©çš„Captionæª¢æ¸¬"""
        logger.info("ğŸ” æ¸¬è©¦1: Captionæª¢æ¸¬ - æè¿°æ€§æŒ‡ç¤ºè©")
        
        test_cases = [
            ("ä¸‹åˆ—åœ–è¡¨æè¿°äº†å·¥ä½œå°å•†å‹™åç‰‡é€²è¡Œæ‹¼ç‰ˆçš„æ–¹å¼ã€‚", 0.7),  # æ®µè½102åŸæ–‡
            ("ä»¥ä¸‹åœ–ç¤ºèªªæ˜äº†æ“ä½œæµç¨‹ã€‚", 0.7),
            ("ä¸Šåœ–é¡¯ç¤ºäº†æ•¸æ“šåˆ†æçµæœã€‚", 0.7),
            ("åœ–1é¡¯ç¤ºäº†éŠ·å”®è¶¨å‹¢", 0.9),  # ç·¨è™Ÿå¼•ç”¨æ‡‰è©²æ›´é«˜åˆ†
            ("Figure 1 shows the trend", 0.9),
            ("â€¢ 11 x 17 é‡ç£…ç´™ï¼Œå¦‚å¡ç‰‡ç´™å¼µ", 0.1),  # æ™®é€šæ–‡æœ¬
        ]
        
        results = []
        passed = 0
        
        for text_content, expected_min_score in test_cases:
            text_block = TextBlock(
                id="test_text",
                content=text_content,
                content_type=ContentType.PARAGRAPH,
                page_number=1,
                bbox=BoundingBox(x=100, y=200, width=300, height=30)
            )
            
            image = ImageContent(
                id="test_image",
                filename="test.jpg",
                format=ImageFormat.JPEG,
                data=b"fake_data",
                page_number=1,
                bbox=BoundingBox(x=100, y=250, width=300, height=100),
                alt_text="æ¸¬è©¦åœ–ç‰‡"
            )
            
            caption_matches = self.caption_detector.detect_captions(
                text_content, text_block.bbox, image.bbox
            )
            caption_score = max((match.confidence for match in caption_matches), default=0.0)
            
            test_passed = caption_score >= expected_min_score
            if test_passed:
                passed += 1
            
            result = {
                'text': text_content,
                'expected_min_score': expected_min_score,
                'actual_score': caption_score,
                'passed': test_passed,
                'caption_matches': len(caption_matches)
            }
            results.append(result)
            
            logger.info(f"   æ–‡æœ¬: '{text_content[:30]}...' | "
                       f"æœŸæœ›â‰¥{expected_min_score:.1f} | å¯¦éš›: {caption_score:.3f} | "
                       f"{'âœ…' if test_passed else 'âŒ'}")
        
        self.test_results['total_tests'] += len(test_cases)
        self.test_results['passed_tests'] += passed
        self.test_results['failed_tests'] += len(test_cases) - passed
        
        return {
            'test_name': 'Captionæª¢æ¸¬ - æè¿°æ€§æŒ‡ç¤ºè©',
            'total_cases': len(test_cases),
            'passed': passed,
            'success_rate': passed / len(test_cases),
            'details': results
        }
    
    def test_spatial_relationship_priority(self) -> Dict[str, Any]:
        """æ¸¬è©¦ç©ºé–“é—œä¿‚å„ªå…ˆç´šè¨ˆç®—"""
        logger.info("ğŸ” æ¸¬è©¦2: ç©ºé–“é—œä¿‚å„ªå…ˆç´š")
        
        text_blocks, images = self.create_test_scenario_paragraph_102()
        target_image = images[0]
        
        results = []
        
        for text_block in text_blocks:
            # è¨ˆç®—ç©ºé–“ç‰¹å¾µ
            spatial_features = self.spatial_analyzer.calculate_spatial_features(
                text_block.bbox, target_image.bbox
            )
            
            # å¢å¼·ç©ºé–“åˆ†æ
            context_info = {
                'all_elements': text_blocks + images,
                'text_content': text_block.content
            }
            
            try:
                enhanced_result = self.spatial_analyzer.calculate_enhanced_spatial_features(
                    text_block.bbox, target_image.bbox, context_info
                )
                enhanced_score = enhanced_result['final_score']
                spatial_relationship = enhanced_result['details']['relationship']
            except Exception as e:
                logger.warning(f"å¢å¼·ç©ºé–“åˆ†æå¤±æ•—: {e}")
                enhanced_score = 0.5
                spatial_relationship = "unknown"
            
            result = {
                'text_id': text_block.id,
                'text_content': text_block.content[:50],
                'center_distance': spatial_features.center_distance if spatial_features else 0,
                'min_distance': spatial_features.min_distance if spatial_features else 0,
                'alignment_score': spatial_features.alignment_score if spatial_features else 0,
                'enhanced_spatial_score': enhanced_score,
                'spatial_relationship': spatial_relationship,
                'is_above_image': text_block.bbox.bottom <= target_image.bbox.top
            }
            results.append(result)
            
            logger.info(f"   {text_block.id}: {text_block.content[:30]}... | "
                       f"ç©ºé–“åˆ†æ•¸: {enhanced_score:.3f} | é—œä¿‚: {spatial_relationship}")
        
        # é©—è­‰æ®µè½102æ‡‰è©²æœ‰åˆç†çš„ç©ºé–“é—œä¿‚
        p102_result = next((r for r in results if r['text_id'] == 'p102'), None)
        test_passed = p102_result and p102_result['is_above_image'] and p102_result['enhanced_spatial_score'] > 0.3
        
        self.test_results['total_tests'] += 1
        if test_passed:
            self.test_results['passed_tests'] += 1
        else:
            self.test_results['failed_tests'] += 1
        
        return {
            'test_name': 'ç©ºé–“é—œä¿‚å„ªå…ˆç´š',
            'passed': test_passed,
            'p102_spatial_score': p102_result['enhanced_spatial_score'] if p102_result else 0,
            'details': results
        }
    
    def test_candidate_ranking_logic(self) -> Dict[str, Any]:
        """æ¸¬è©¦å€™é¸æ’åºå™¨é‚è¼¯"""
        logger.info("ğŸ” æ¸¬è©¦3: CandidateRankeræ™ºèƒ½æ’åº")
        
        text_blocks, images = self.create_test_scenario_paragraph_102()
        target_image = images[0]
        
        # æº–å‚™å€™é¸æ–‡æœ¬
        text_candidates = [
            {
                'id': tb.id,
                'content': tb.content,
                'bbox': tb.bbox
            }
            for tb in text_blocks
        ]
        
        context_info = {
            'all_elements': text_blocks + images,
            'document_type': 'manual'
        }
        
        # åŸ·è¡Œå€™é¸æ’åº
        ranked_candidates = self.candidate_ranker.rank_candidates(
            text_candidates=text_candidates,
            image_bbox=target_image.bbox,
            image_content=target_image.alt_text,
            context_info=context_info
        )
        
        results = []
        for i, candidate in enumerate(ranked_candidates):
            result = {
                'rank': candidate.rank,
                'text_id': candidate.text_id,
                'text_content': candidate.text_content[:50],
                'final_score': candidate.scores.final_score,
                'caption_score': candidate.scores.caption_score,
                'spatial_score': candidate.scores.spatial_score,
                'semantic_score': candidate.scores.semantic_score,
                'is_recommended': candidate.is_recommended,
                'quality': candidate.scores.quality.value,
                'reasoning': candidate.reasoning[:100] if candidate.reasoning else ""
            }
            results.append(result)
            
            logger.info(f"   æ’å{candidate.rank}: {candidate.text_id} | "
                       f"ç¸½åˆ†: {candidate.scores.final_score:.3f} | "
                       f"Caption: {candidate.scores.caption_score:.3f} | "
                       f"æ¨è–¦: {'âœ…' if candidate.is_recommended else 'âŒ'}")
        
        # é©—è­‰æ®µè½102æ˜¯å¦ç²å¾—è¼ƒé«˜æ’å
        p102_candidate = next((c for c in ranked_candidates if c.text_id == 'p102'), None)
        test_passed = p102_candidate and p102_candidate.rank <= 3 and p102_candidate.is_recommended
        
        self.test_results['total_tests'] += 1
        if test_passed:
            self.test_results['passed_tests'] += 1
        else:
            self.test_results['failed_tests'] += 1
        
        return {
            'test_name': 'CandidateRankeræ™ºèƒ½æ’åº',
            'passed': test_passed,
            'p102_rank': p102_candidate.rank if p102_candidate else None,
            'p102_recommended': p102_candidate.is_recommended if p102_candidate else False,
            'total_candidates': len(ranked_candidates),
            'recommended_count': sum(1 for c in ranked_candidates if c.is_recommended),
            'details': results
        }
    
    def test_complete_association_workflow(self) -> Dict[str, Any]:
        """æ¸¬è©¦å®Œæ•´é—œè¯åˆ†æå·¥ä½œæµç¨‹"""
        logger.info("ğŸ” æ¸¬è©¦4: å®Œæ•´é—œè¯åˆ†æå·¥ä½œæµç¨‹")
        
        text_blocks, images = self.create_test_scenario_paragraph_102()
        target_image = images[0]
        
        # åŸ·è¡Œå®Œæ•´é—œè¯åˆ†æ
        associations = []
        
        for text_block in text_blocks:
            # 1. Captionæª¢æ¸¬
            caption_matches = self.caption_detector.detect_captions(
                text_block.content, text_block.bbox, target_image.bbox
            )
            caption_score = max((match.confidence for match in caption_matches), default=0.0)
            
            # 2. ç©ºé–“é—œä¿‚åˆ†æ
            spatial_features = self.spatial_analyzer.calculate_spatial_features(
                text_block.bbox, target_image.bbox
            )
            
            # 3. èªç¾©ç›¸ä¼¼åº¦åˆ†æ
            semantic_score = self.semantic_analyzer.calculate_similarity(
                text_block.content, 
                target_image.alt_text or f"Image {target_image.id}"
            )
            
            # 4. å¢å¼·ç©ºé–“åˆ†æ
            context_info = {
                'all_elements': text_blocks + images,
                'text_content': text_block.content
            }
            
            try:
                enhanced_result = self.spatial_analyzer.calculate_enhanced_spatial_features(
                    text_block.bbox, target_image.bbox, context_info
                )
                enhanced_spatial_score = enhanced_result['final_score']
                layout_score = enhanced_result['component_scores'].get('alignment', 0.5)
                proximity_score = enhanced_result['component_scores'].get('distance', 0.5)
            except Exception:
                enhanced_spatial_score = 0.5
                layout_score = 0.5
                proximity_score = 0.5
            
            # 5. ç¶œåˆè©•åˆ†
            final_score, details = self.association_scorer.calculate_simple_score(
                caption_score=caption_score,
                spatial_score=enhanced_spatial_score,
                semantic_score=semantic_score,
                layout_score=layout_score,
                proximity_score=proximity_score
            )
            
            # 6. å‰µå»ºé—œè¯è¨˜éŒ„
            association = {
                "text_block_id": text_block.id,
                "image_id": target_image.id,
                "final_score": final_score,
                "caption_score": caption_score,
                "spatial_score": enhanced_spatial_score,
                "semantic_score": semantic_score,
                "layout_score": layout_score,
                "proximity_score": proximity_score,
                "association_type": "caption" if caption_score > 0.5 else "spatial",
                "details": details
            }
            
            associations.append(association)
        
        # 7. é—œè¯å„ªåŒ–
        optimized_associations = self.association_optimizer.optimize_associations(
            associations=associations,
            images=images,
            text_blocks=text_blocks
        )
        
        # åˆ†æçµæœ
        results = []
        for assoc in optimized_associations:
            result = {
                'text_id': assoc['text_block_id'],
                'final_score': assoc['final_score'],
                'adjusted_score': assoc.get('adjusted_score', assoc['final_score']),
                'caption_score': assoc['caption_score'],
                'association_type': assoc['association_type'],
                'caption_boosted': assoc.get('caption_boosted', False),
                'quality_grade': assoc.get('quality_grade', 'unknown')
            }
            results.append(result)
            
            logger.info(f"   {assoc['text_block_id']}: åˆ†æ•¸ {assoc['final_score']:.3f} â†’ "
                       f"{assoc.get('adjusted_score', assoc['final_score']):.3f} | "
                       f"é¡å‹: {assoc['association_type']} | "
                       f"CaptionåŠ æˆ: {'âœ…' if assoc.get('caption_boosted', False) else 'âŒ'}")
        
        # é©—è­‰æ®µè½102çš„è™•ç†çµæœ
        p102_assoc = next((a for a in optimized_associations if a['text_block_id'] == 'p102'), None)
        
        if p102_assoc:
            test_passed = (
                p102_assoc['caption_score'] > 0.3 and  # Captionæª¢æ¸¬åˆ°
                p102_assoc['association_type'] == 'caption' and  # é¡å‹æ­£ç¢º
                p102_assoc.get('caption_boosted', False)  # ç²å¾—CaptionåŠ æˆ
            )
        else:
            test_passed = False
        
        self.test_results['total_tests'] += 1
        if test_passed:
            self.test_results['passed_tests'] += 1
        else:
            self.test_results['failed_tests'] += 1
        
        return {
            'test_name': 'å®Œæ•´é—œè¯åˆ†æå·¥ä½œæµç¨‹',
            'passed': test_passed,
            'total_associations': len(associations),
            'optimized_associations': len(optimized_associations),
            'p102_found': p102_assoc is not None,
            'p102_caption_score': p102_assoc['caption_score'] if p102_assoc else 0,
            'p102_association_type': p102_assoc['association_type'] if p102_assoc else 'none',
            'p102_caption_boosted': p102_assoc.get('caption_boosted', False) if p102_assoc else False,
            'details': results
        }
    
    def test_association_type_consistency(self) -> Dict[str, Any]:
        """æ¸¬è©¦é—œè¯é¡å‹ä¸€è‡´æ€§ï¼ˆCaptionæª¢æ¸¬èˆ‡é¡å‹æ¨™è¨˜åŒæ­¥ï¼‰"""
        logger.info("ğŸ” æ¸¬è©¦5: é—œè¯é¡å‹ä¸€è‡´æ€§æª¢æŸ¥")
        
        # æ¸¬è©¦æ¡ˆä¾‹ï¼šæ˜ç¢ºçš„CaptionæŒ‡ç¤ºè©
        test_cases = [
            "ä¸‹åˆ—åœ–è¡¨æè¿°äº†å·¥ä½œå°å•†å‹™åç‰‡é€²è¡Œæ‹¼ç‰ˆçš„æ–¹å¼ã€‚",
            "åœ–1é¡¯ç¤ºäº†éŠ·å”®è¶¨å‹¢è®ŠåŒ–",
            "ä»¥ä¸‹åœ–ç¤ºèªªæ˜äº†æ“ä½œæµç¨‹",
            "Figure 2 demonstrates the process"
        ]
        
        results = []
        consistent_count = 0
        
        for text_content in test_cases:
            text_block = TextBlock(
                id=f"test_{len(results)}",
                content=text_content,
                content_type=ContentType.PARAGRAPH,
                page_number=1,
                bbox=BoundingBox(x=100, y=200, width=400, height=30)
            )
            
            image = ImageContent(
                id="test_image",
                filename="test.jpg",
                format=ImageFormat.JPEG,
                data=b"fake_data",
                page_number=1,
                bbox=BoundingBox(x=100, y=250, width=400, height=130),
                alt_text="æ¸¬è©¦åœ–ç‰‡"
            )
            
            # 1. Captionæª¢æ¸¬
            caption_matches = self.caption_detector.detect_captions(
                text_content, text_block.bbox, image.bbox
            )
            caption_score = max((match.confidence for match in caption_matches), default=0.0)
            
            # 2. åˆå§‹é—œè¯é¡å‹æ±ºå®š
            initial_type = "caption" if caption_score > 0.5 else "spatial"
            
            # 3. æ¨¡æ“¬å„ªåŒ–éç¨‹
            association = {
                "text_block_id": text_block.id,
                "image_id": image.id,
                "final_score": 0.6,
                "caption_score": caption_score,
                "spatial_score": 0.5,
                "semantic_score": 0.4,
                "layout_score": 0.5,
                "proximity_score": 0.5,
                "association_type": initial_type
            }
            
            # 4. é—œè¯å„ªåŒ–
            optimized = self.association_optimizer.optimize_associations(
                associations=[association],
                images=[image],
                text_blocks=[text_block]
            )
            
            if optimized:
                final_type = optimized[0]['association_type']
                caption_boosted = optimized[0].get('caption_boosted', False)
                
                # æª¢æŸ¥ä¸€è‡´æ€§
                is_consistent = (
                    (caption_score > 0.3 and final_type == 'caption') or
                    (caption_score <= 0.3 and final_type == 'spatial')
                )
                
                if is_consistent:
                    consistent_count += 1
            else:
                final_type = 'none'
                caption_boosted = False
                is_consistent = False
            
            result = {
                'text_content': text_content,
                'caption_score': caption_score,
                'initial_type': initial_type,
                'final_type': final_type,
                'caption_boosted': caption_boosted,
                'is_consistent': is_consistent
            }
            results.append(result)
            
            logger.info(f"   æ–‡æœ¬: '{text_content[:40]}...' | "
                       f"Captionåˆ†æ•¸: {caption_score:.3f} | "
                       f"é¡å‹: {initial_type} â†’ {final_type} | "
                       f"ä¸€è‡´æ€§: {'âœ…' if is_consistent else 'âŒ'}")
        
        test_passed = consistent_count == len(test_cases)
        
        self.test_results['total_tests'] += 1
        if test_passed:
            self.test_results['passed_tests'] += 1
        else:
            self.test_results['failed_tests'] += 1
        
        return {
            'test_name': 'é—œè¯é¡å‹ä¸€è‡´æ€§æª¢æŸ¥',
            'passed': test_passed,
            'consistent_count': consistent_count,
            'total_cases': len(test_cases),
            'consistency_rate': consistent_count / len(test_cases),
            'details': results
        }
    
    def run_all_tests(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        logger.info("ğŸš€ é–‹å§‹é—œè¯åˆ†æå°ˆé …æ¸¬è©¦")
        
        test_functions = [
            self.test_caption_detection_descriptive_words,
            self.test_spatial_relationship_priority,
            self.test_candidate_ranking_logic,
            self.test_complete_association_workflow,
            self.test_association_type_consistency
        ]
        
        all_results = []
        
        for test_func in test_functions:
            try:
                result = test_func()
                self.test_results['test_details'].append(result)
                all_results.append(result)
                logger.info(f"âœ… {result['test_name']} å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ {test_func.__name__} æ¸¬è©¦å¤±æ•—: {e}")
                self.test_results['failed_tests'] += 1
                all_results.append({
                    'test_name': test_func.__name__,
                    'passed': False,
                    'error': str(e)
                })
        
        # è¨ˆç®—ç¸½é«”çµæœ
        self.test_results['success_rate'] = (
            self.test_results['passed_tests'] / self.test_results['total_tests'] 
            if self.test_results['total_tests'] > 0 else 0
        )
        
        return {
            'summary': self.test_results,
            'individual_results': all_results
        }
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        summary = results['summary']
        
        report = f"""
# é—œè¯åˆ†æå°ˆé …æ¸¬è©¦å ±å‘Š

## ğŸ“Š æ¸¬è©¦ç¸½çµ

- **æ¸¬è©¦æ™‚é–“**: {summary['timestamp']}
- **ç¸½æ¸¬è©¦æ•¸**: {summary['total_tests']}
- **é€šéæ¸¬è©¦**: {summary['passed_tests']}
- **å¤±æ•—æ¸¬è©¦**: {summary['failed_tests']}
- **æˆåŠŸç‡**: {summary['success_rate']:.1%}

## ğŸ“‹ æ¸¬è©¦è©³æƒ…

"""
        
        for test_detail in summary['test_details']:
            report += f"### {test_detail['test_name']}\n"
            report += f"- **çµæœ**: {'âœ… é€šé' if test_detail['passed'] else 'âŒ å¤±æ•—'}\n"
            
            if 'success_rate' in test_detail:
                report += f"- **æˆåŠŸç‡**: {test_detail['success_rate']:.1%}\n"
            
            if 'details' in test_detail and isinstance(test_detail['details'], list):
                report += f"- **è©³ç´°çµæœ**: {len(test_detail['details'])} å€‹æ¸¬è©¦æ¡ˆä¾‹\n"
            
            report += "\n"
        
        # é‡å°æ®µè½102å•é¡Œçš„ç‰¹åˆ¥åˆ†æ
        report += """
## ğŸ¯ æ®µè½102å•é¡Œåˆ†æ

åŸºæ–¼æ¸¬è©¦çµæœçš„åˆ†æï¼š
1. **Captionæª¢æ¸¬**: æè¿°æ€§æŒ‡ç¤ºè©çš„æª¢æ¸¬æº–ç¢ºæ€§
2. **ç©ºé–“å„ªå…ˆ**: ä¸Šæ–¹æ–‡æœ¬çš„ç©ºé–“é—œä¿‚è¨ˆç®—
3. **å€™é¸æ’åº**: CandidateRankerçš„æ™ºèƒ½æ’åºæ•ˆæœ
4. **é¡å‹ä¸€è‡´**: Captionæª¢æ¸¬èˆ‡é—œè¯é¡å‹çš„åŒæ­¥æ€§
5. **å®Œæ•´æµç¨‹**: ç«¯åˆ°ç«¯çš„é—œè¯åˆ†ææº–ç¢ºæ€§

## ğŸ”§ æ”¹é€²å»ºè­°

åŸºæ–¼æ¸¬è©¦ç™¼ç¾çš„å•é¡Œï¼Œå»ºè­°ï¼š
1. å¢å¼·æè¿°æ€§CaptionæŒ‡ç¤ºè©çš„æª¢æ¸¬æ¨¡å¼
2. å„ªåŒ–ç©ºé–“é—œä¿‚çš„ä½ç½®åŠ æ¬Šé‚è¼¯
3. ç¢ºä¿é—œè¯é¡å‹èˆ‡Captionæª¢æ¸¬çµæœçš„åŒæ­¥
4. åŠ å¼·å€™é¸æ’åºä¸­çš„ä¸Šæ–¹å„ªå…ˆè¦å‰‡

"""
        
        return report


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é—œè¯åˆ†æå°ˆé …æ¸¬è©¦å•Ÿå‹•")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ¸¬è©¦
    test_runner = AssociationAnalysisTest()
    
    # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
    results = test_runner.run_all_tests()
    
    # ç”Ÿæˆå ±å‘Š
    report = test_runner.generate_report(results)
    
    # ä¿å­˜çµæœ
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜JSONçµæœ
    json_file = output_dir / "association_analysis_test_results.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    # ä¿å­˜Markdownå ±å‘Š
    report_file = output_dir / "association_analysis_test_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    # è¼¸å‡ºçµæœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æ¸¬è©¦å®Œæˆ!")
    print(f"ç¸½æ¸¬è©¦æ•¸: {results['summary']['total_tests']}")
    print(f"é€šéæ¸¬è©¦: {results['summary']['passed_tests']}")
    print(f"å¤±æ•—æ¸¬è©¦: {results['summary']['failed_tests']}")
    print(f"æˆåŠŸç‡: {results['summary']['success_rate']:.1%}")
    print(f"\nğŸ“ è©³ç´°çµæœä¿å­˜è‡³:")
    print(f"   - JSON: {json_file}")
    print(f"   - å ±å‘Š: {report_file}")
    
    # é‡é»åˆ†ææ®µè½102é¡ä¼¼å•é¡Œ
    print("\nğŸ¯ æ®µè½102å•é¡Œé‡é»åˆ†æ:")
    
    for test_detail in results['summary']['test_details']:
        if 'p102' in str(test_detail):
            print(f"   - {test_detail['test_name']}: {'âœ…' if test_detail['passed'] else 'âŒ'}")
    
    print("\n" + "=" * 60)
    
    return results['summary']['success_rate']


if __name__ == "__main__":
    success_rate = main()
    # è¿”å›é©ç•¶çš„é€€å‡ºç¢¼
    sys.exit(0 if success_rate >= 0.8 else 1)