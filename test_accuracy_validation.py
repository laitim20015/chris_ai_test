#!/usr/bin/env python3
"""
æº–ç¢ºæ€§é©—è­‰æ¸¬è©¦
Accuracy Validation Test

é©—è­‰ç©ºé–“åˆ†ææ”¹é€²çš„æº–ç¢ºæ€§å’Œå¯é æ€§ï¼ŒåŒ…æ‹¬ï¼š
1. ç®—æ³•æº–ç¢ºæ€§é©—è­‰
2. é‚Šç•Œæƒ…æ³æ¸¬è©¦
3. å›æ­¸æ¸¬è©¦
4. çµæœä¸€è‡´æ€§é©—è­‰
"""

import sys
import os
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Tuple

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

from src.association.spatial_analyzer import (
    enhanced_spatial_scoring, enhanced_spatial_scoring_optimized,
    analyze_vertical_relationship, calculate_horizontal_overlap,
    check_intervening_elements, calculate_normalized_distance
)
from src.association.allen_logic import BoundingBox
from src.association.candidate_ranker import CandidateRanker
from src.main import DocumentProcessor
from src.parsers.base import TextBlock, ImageContent

def create_accuracy_test_cases() -> List[Dict[str, Any]]:
    """å‰µå»ºæº–ç¢ºæ€§æ¸¬è©¦ç”¨ä¾‹"""
    test_cases = [
        # Test Case 1: ç†æƒ³çš„åœ–æ–‡é—œè¯ (Captionåœ¨åœ–ç‰‡ä¸‹æ–¹ï¼Œå®Œç¾å°é½Š)
        {
            'name': 'ç†æƒ³é—œè¯_Captionä¸‹æ–¹',
            'text_bbox': BoundingBox(x=100, y=320, width=300, height=30),
            'image_bbox': BoundingBox(x=120, y=200, width=260, height=100),
            'text_content': 'Figure 1: This diagram shows the complete workflow process.',
            'expected_score_range': (0.7, 1.0),
            'expected_caption_detected': True,
            'description': 'Captionæ–‡æœ¬ä½æ–¼åœ–ç‰‡æ­£ä¸‹æ–¹ï¼Œå®Œç¾æ°´å¹³å°é½Š'
        },
        
        # Test Case 2: è‰¯å¥½é—œè¯ (æ–‡æœ¬åœ¨åœ–ç‰‡ä¸Šæ–¹ï¼Œéƒ¨åˆ†å°é½Š)
        {
            'name': 'è‰¯å¥½é—œè¯_æ–‡æœ¬ä¸Šæ–¹',
            'text_bbox': BoundingBox(x=110, y=150, width=280, height=30),
            'image_bbox': BoundingBox(x=100, y=200, width=300, height=100),
            'text_content': 'The following diagram illustrates the key concepts.',
            'expected_score_range': (0.4, 0.7),
            'expected_caption_detected': False,
            'description': 'æ™®é€šæ–‡æœ¬åœ¨åœ–ç‰‡ä¸Šæ–¹ï¼Œæœ‰ä¸€å®šæ°´å¹³é‡ç–Š'
        },
        
        # Test Case 3: è¼ƒå·®é—œè¯ (è·é›¢è¼ƒé ï¼Œç„¡å°é½Š)
        {
            'name': 'è¼ƒå·®é—œè¯_è·é›¢é ',
            'text_bbox': BoundingBox(x=50, y=500, width=200, height=30),
            'image_bbox': BoundingBox(x=400, y=200, width=150, height=80),
            'text_content': 'This text is not related to any specific image.',
            'expected_score_range': (0.0, 0.3),
            'expected_caption_detected': False,
            'description': 'æ–‡æœ¬å’Œåœ–ç‰‡è·é›¢å¾ˆé ï¼Œæ²’æœ‰å°é½Š'
        },
        
        # Test Case 4: è·¨æ¬„ä½é—œè¯ (æ‡‰è©²è¢«æ‡²ç½°)
        {
            'name': 'è·¨æ¬„ä½é—œè¯',
            'text_bbox': BoundingBox(x=50, y=300, width=150, height=30),
            'image_bbox': BoundingBox(x=350, y=280, width=150, height=80),
            'text_content': 'Figure 2: Cross-column caption text.',
            'expected_score_range': (0.2, 0.5),
            'expected_caption_detected': True,
            'description': 'Captionæ–‡æœ¬å’Œåœ–ç‰‡åœ¨ä¸åŒæ¬„ä½ä¸­'
        },
        
        # Test Case 5: å‚ç›´å°é½Šä½†æ°´å¹³é‡ç–Šå·®
        {
            'name': 'å‚ç›´å°é½Š_æ°´å¹³ä¸é‡ç–Š',
            'text_bbox': BoundingBox(x=400, y=320, width=180, height=30),
            'image_bbox': BoundingBox(x=100, y=200, width=200, height=100),
            'text_content': 'Table 1: Summary of experimental results.',
            'expected_score_range': (0.1, 0.4),
            'expected_caption_detected': True,
            'description': 'å‚ç›´ä½ç½®åˆé©ä½†æ°´å¹³ä½ç½®ç›¸è·è¼ƒé '
        },
        
        # Test Case 6: å®Œç¾Captioné—œè¯
        {
            'name': 'å®Œç¾Captioné—œè¯',
            'text_bbox': BoundingBox(x=100, y=310, width=300, height=25),
            'image_bbox': BoundingBox(x=100, y=200, width=300, height=100),
            'text_content': 'Figure 3: Detailed analysis of the proposed algorithm performance.',
            'expected_score_range': (0.8, 1.0),
            'expected_caption_detected': True,
            'description': 'å®Œç¾çš„Captioné—œè¯ï¼šä½ç½®ã€å°é½Šã€å…§å®¹éƒ½ç†æƒ³'
        }
    ]
    
    return test_cases

def test_algorithm_accuracy():
    """æ¸¬è©¦ç®—æ³•æº–ç¢ºæ€§"""
    print("ğŸ¯ ç®—æ³•æº–ç¢ºæ€§é©—è­‰")
    print("=" * 60)
    
    test_cases = create_accuracy_test_cases()
    results = []
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\næ¸¬è©¦æ¡ˆä¾‹ {i}: {test_case['name']}")
        print(f"æè¿°: {test_case['description']}")
        print(f"æ–‡æœ¬å…§å®¹: {test_case['text_content'][:60]}...")
        
        # å‰µå»ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆåŒ…å«text_contentï¼‰
        context_info = {
            'layout_type': 'double_column' if 'è·¨æ¬„ä½' in test_case['name'] else 'single_column',
            'all_elements': [test_case['text_bbox'], test_case['image_bbox']],
            'page_width': 600,
            'page_height': 800,
            'text_content': test_case['text_content']  # æ·»åŠ æ–‡æœ¬å…§å®¹ä»¥ä¾¿Captionæª¢æ¸¬
        }
        
        # åŸ·è¡Œå®Œæ•´çš„é—œè¯åˆ†æï¼ˆé€šéDocumentProcessorï¼‰
        processor = DocumentProcessor()
        
        # å‰µå»ºæ¸¬è©¦ç”¨çš„TextBlockå’ŒImageContent
        from src.parsers.base import ContentType
        text_block = TextBlock(
            id=f"text_{i}",
            content=test_case['text_content'],
            content_type=ContentType.PARAGRAPH,
            bbox=test_case['text_bbox'],
            font_size=12.0,
            font_name="Arial"
        )
        
        from src.parsers.base import ImageFormat
        image = ImageContent(
            id=f"image_{i}",
            filename="test_image.jpg",
            format=ImageFormat.JPEG,
            data=b"test_data",  # æ¸¬è©¦ç”¨å‡æ•¸æ“š
            bbox=test_case['image_bbox']
        )
        
        # åŸ·è¡Œå®Œæ•´çš„é—œè¯åˆ†æ
        result = processor._perform_association_analysis(text_block, image)
        
        final_score = result['final_score']
        expected_min, expected_max = test_case['expected_score_range']
        
        # é©—è­‰åˆ†æ•¸ç¯„åœ
        score_in_range = expected_min <= final_score <= expected_max
        
        # é©—è­‰Captionæª¢æ¸¬ï¼ˆç°¡å–®æª¢æŸ¥æ–‡æœ¬å…§å®¹ï¼‰
        has_caption = any(pattern in test_case['text_content'].lower() 
                         for pattern in ['figure', 'table', 'chart', 'diagram'])
        caption_correct = has_caption == test_case['expected_caption_detected']
        
        # è¨˜éŒ„çµæœ
        test_result = {
            'name': test_case['name'],
            'score': final_score,
            'expected_range': test_case['expected_score_range'],
            'score_in_range': score_in_range,
            'caption_detected': has_caption,
            'caption_correct': caption_correct,
            'passed': score_in_range and caption_correct,
            'component_scores': {
                'caption': result['caption_score'],
                'spatial': result['spatial_score'], 
                'semantic': result['semantic_score'],
                'layout': result['layout_score'],
                'proximity': result['proximity_score']
            }
        }
        results.append(test_result)
        
        # é¡¯ç¤ºçµæœ
        print(f"  æœ€çµ‚åˆ†æ•¸: {final_score:.3f} (æœŸæœ›: {expected_min:.1f}-{expected_max:.1f})")
        print(f"  åˆ†æ•¸ç¯„åœ: {'âœ…' if score_in_range else 'âŒ'}")
        print(f"  Captionæª¢æ¸¬: {'âœ…' if caption_correct else 'âŒ'}")
        print(f"  æ•´é«”çµæœ: {'âœ… PASS' if test_result['passed'] else 'âŒ FAIL'}")
        
        # é¡¯ç¤ºçµ„ä»¶åˆ†æ•¸ï¼ˆå¾å®Œæ•´é—œè¯åˆ†æçµæœï¼‰
        print(f"  çµ„ä»¶åˆ†æ•¸: Caption={result['caption_score']:.3f}, "
              f"Spatial={result['spatial_score']:.3f}, "
              f"Semantic={result['semantic_score']:.3f}, "
              f"Layout={result['layout_score']:.3f}, "
              f"Proximity={result['proximity_score']:.3f}")
        print("-" * 40)
    
    return results

def test_edge_cases():
    """æ¸¬è©¦é‚Šç•Œæƒ…æ³"""
    print("\nğŸ”¬ é‚Šç•Œæƒ…æ³æ¸¬è©¦")
    print("=" * 60)
    
    edge_cases = [
        # æ¥µå°é‚Šç•Œæ¡†
        {
            'name': 'æ¥µå°é‚Šç•Œæ¡†',
            'text_bbox': BoundingBox(x=100, y=300, width=1, height=1),
            'image_bbox': BoundingBox(x=101, y=301, width=1, height=1),
            'should_not_crash': True
        },
        
        # æ¥µå¤§é‚Šç•Œæ¡†
        {
            'name': 'æ¥µå¤§é‚Šç•Œæ¡†',
            'text_bbox': BoundingBox(x=0, y=0, width=10000, height=10000),
            'image_bbox': BoundingBox(x=5000, y=5000, width=10000, height=10000),
            'should_not_crash': True
        },
        
        # è² åæ¨™
        {
            'name': 'è² åæ¨™é‚Šç•Œæ¡†',
            'text_bbox': BoundingBox(x=-100, y=-100, width=200, height=50),
            'image_bbox': BoundingBox(x=-50, y=-50, width=150, height=80),
            'should_not_crash': True
        },
        
        # é›¶å°ºå¯¸
        {
            'name': 'é›¶å°ºå¯¸é‚Šç•Œæ¡†',
            'text_bbox': BoundingBox(x=100, y=300, width=0, height=0),
            'image_bbox': BoundingBox(x=120, y=280, width=100, height=80),
            'should_not_crash': True
        },
        
        # å®Œå…¨é‡ç–Š
        {
            'name': 'å®Œå…¨é‡ç–Šé‚Šç•Œæ¡†',
            'text_bbox': BoundingBox(x=100, y=200, width=200, height=100),
            'image_bbox': BoundingBox(x=100, y=200, width=200, height=100),
            'should_not_crash': True
        }
    ]
    
    results = []
    
    for edge_case in edge_cases:
        print(f"\næ¸¬è©¦é‚Šç•Œæƒ…æ³: {edge_case['name']}")
        
        try:
            context_info = {
                'layout_type': 'single_column',
                'all_elements': [edge_case['text_bbox'], edge_case['image_bbox']],
                'page_width': 600,
                'page_height': 800
            }
            
            # åŸ·è¡Œæ¸¬è©¦
            result = enhanced_spatial_scoring(
                edge_case['text_bbox'], 
                edge_case['image_bbox'], 
                context_info
            )
            
            score = result['final_score']
            
            # æª¢æŸ¥çµæœæ˜¯å¦åˆç†
            is_valid = (isinstance(score, (int, float)) and 
                       0 <= score <= 1 and 
                       not (score != score))  # æª¢æŸ¥æ˜¯å¦ç‚º NaN
            
            test_result = {
                'name': edge_case['name'],
                'passed': True,
                'score': score,
                'valid_score': is_valid,
                'error': None
            }
            
            print(f"  çµæœ: âœ… æ­£å¸¸åŸ·è¡Œ")
            print(f"  åˆ†æ•¸: {score:.3f}")
            print(f"  åˆ†æ•¸æœ‰æ•ˆ: {'âœ…' if is_valid else 'âŒ'}")
            
        except Exception as e:
            test_result = {
                'name': edge_case['name'],
                'passed': False,
                'score': None,
                'valid_score': False,
                'error': str(e)
            }
            
            print(f"  çµæœ: âŒ ç•°å¸¸: {e}")
        
        results.append(test_result)
    
    return results

def test_consistency():
    """æ¸¬è©¦çµæœä¸€è‡´æ€§"""
    print("\nğŸ”„ çµæœä¸€è‡´æ€§æ¸¬è©¦")
    print("=" * 60)
    
    # å‰µå»ºæ¸¬è©¦æ¡ˆä¾‹
    text_bbox = BoundingBox(x=100, y=320, width=300, height=30)
    image_bbox = BoundingBox(x=120, y=200, width=260, height=100)
    context_info = {
        'layout_type': 'single_column',
        'all_elements': [text_bbox, image_bbox],
        'page_width': 600,
        'page_height': 800
    }
    
    # å¤šæ¬¡é‹è¡ŒåŒæ¨£çš„æ¸¬è©¦
    num_runs = 10
    scores = []
    
    print(f"åŸ·è¡Œ {num_runs} æ¬¡ç›¸åŒçš„åˆ†æ...")
    
    for i in range(num_runs):
        result = enhanced_spatial_scoring(text_bbox, image_bbox, context_info)
        scores.append(result['final_score'])
    
    # è¨ˆç®—ä¸€è‡´æ€§çµ±è¨ˆ
    min_score = min(scores)
    max_score = max(scores)
    avg_score = sum(scores) / len(scores)
    variance = sum((s - avg_score) ** 2 for s in scores) / len(scores)
    std_dev = variance ** 0.5
    
    # åˆ¤æ–·ä¸€è‡´æ€§
    is_consistent = (max_score - min_score) < 0.001  # å·®ç•°å°æ–¼0.1%
    
    print(f"\nä¸€è‡´æ€§çµæœ:")
    print(f"  æœ€å°åˆ†æ•¸: {min_score:.6f}")
    print(f"  æœ€å¤§åˆ†æ•¸: {max_score:.6f}")
    print(f"  å¹³å‡åˆ†æ•¸: {avg_score:.6f}")
    print(f"  æ¨™æº–å·®: {std_dev:.6f}")
    print(f"  åˆ†æ•¸ç¯„åœ: {max_score - min_score:.6f}")
    print(f"  ä¸€è‡´æ€§: {'âœ… é€šé' if is_consistent else 'âŒ å¤±æ•—'}")
    
    return {
        'passed': is_consistent,
        'scores': scores,
        'statistics': {
            'min': min_score,
            'max': max_score,
            'avg': avg_score,
            'std_dev': std_dev,
            'range': max_score - min_score
        }
    }

def test_performance_vs_accuracy():
    """æ¸¬è©¦æ€§èƒ½èˆ‡æº–ç¢ºæ€§çš„å¹³è¡¡"""
    print("\nâš–ï¸  æ€§èƒ½èˆ‡æº–ç¢ºæ€§å¹³è¡¡æ¸¬è©¦")
    print("=" * 60)
    
    # å‰µå»ºæ¸¬è©¦æ¡ˆä¾‹
    text_bbox = BoundingBox(x=100, y=320, width=300, height=30)
    image_bbox = BoundingBox(x=120, y=200, width=260, height=100)
    context_info = {
        'layout_type': 'single_column',
        'all_elements': [text_bbox, image_bbox],
        'page_width': 600,
        'page_height': 800
    }
    
    import time
    
    # æ¸¬è©¦æ¨™æº–ç®—æ³•
    start_time = time.time()
    result1 = enhanced_spatial_scoring(text_bbox, image_bbox, context_info)
    standard_time = time.time() - start_time
    
    # æ¸¬è©¦å„ªåŒ–ç®—æ³•
    start_time = time.time()
    result2 = enhanced_spatial_scoring_optimized(text_bbox, image_bbox, context_info, enable_cache=True)
    optimized_time = time.time() - start_time
    
    # æ¯”è¼ƒçµæœ
    score_diff = abs(result1['final_score'] - result2['final_score'])
    time_speedup = standard_time / max(optimized_time, 0.001)
    
    print(f"æ¨™æº–ç®—æ³•:")
    print(f"  æ™‚é–“: {standard_time:.6f}s")
    print(f"  åˆ†æ•¸: {result1['final_score']:.6f}")
    
    print(f"\nå„ªåŒ–ç®—æ³•:")
    print(f"  æ™‚é–“: {optimized_time:.6f}s")
    print(f"  åˆ†æ•¸: {result2['final_score']:.6f}")
    
    print(f"\næ¯”è¼ƒçµæœ:")
    print(f"  åˆ†æ•¸å·®ç•°: {score_diff:.6f}")
    print(f"  é€Ÿåº¦æå‡: {time_speedup:.2f}x")
    print(f"  æº–ç¢ºæ€§ä¿æŒ: {'âœ…' if score_diff < 0.001 else 'âŒ'}")
    
    return {
        'standard_time': standard_time,
        'optimized_time': optimized_time,
        'score_diff': score_diff,
        'speedup': time_speedup,
        'accuracy_maintained': score_diff < 0.001
    }

def run_accuracy_validation():
    """é‹è¡Œå®Œæ•´çš„æº–ç¢ºæ€§é©—è­‰"""
    print("ğŸ¯ ç©ºé–“åˆ†ææº–ç¢ºæ€§é©—è­‰æ¸¬è©¦")
    print("=" * 70)
    
    results = {}
    
    try:
        # 1. ç®—æ³•æº–ç¢ºæ€§æ¸¬è©¦
        results['accuracy_test'] = test_algorithm_accuracy()
        
        # 2. é‚Šç•Œæƒ…æ³æ¸¬è©¦
        results['edge_cases'] = test_edge_cases()
        
        # 3. ä¸€è‡´æ€§æ¸¬è©¦
        results['consistency'] = test_consistency()
        
        # 4. æ€§èƒ½èˆ‡æº–ç¢ºæ€§å¹³è¡¡æ¸¬è©¦
        results['performance_accuracy'] = test_performance_vs_accuracy()
        
        # ç¸½çµçµæœ
        print(f"\nğŸ¯ æº–ç¢ºæ€§é©—è­‰ç¸½çµ")
        print("=" * 70)
        
        # è¨ˆç®—é€šéç‡
        accuracy_passed = sum(1 for r in results['accuracy_test'] if r['passed'])
        accuracy_total = len(results['accuracy_test'])
        
        edge_passed = sum(1 for r in results['edge_cases'] if r['passed'])
        edge_total = len(results['edge_cases'])
        
        print(f"ğŸ“Š æ¸¬è©¦çµæœ:")
        print(f"  æº–ç¢ºæ€§æ¸¬è©¦: {accuracy_passed}/{accuracy_total} é€šé ({accuracy_passed/accuracy_total*100:.1f}%)")
        print(f"  é‚Šç•Œæƒ…æ³æ¸¬è©¦: {edge_passed}/{edge_total} é€šé ({edge_passed/edge_total*100:.1f}%)")
        print(f"  ä¸€è‡´æ€§æ¸¬è©¦: {'âœ… é€šé' if results['consistency']['passed'] else 'âŒ å¤±æ•—'}")
        print(f"  æ€§èƒ½æº–ç¢ºæ€§å¹³è¡¡: {'âœ… é€šé' if results['performance_accuracy']['accuracy_maintained'] else 'âŒ å¤±æ•—'}")
        
        # è¨ˆç®—ç¸½é«”è©•åˆ†
        total_tests = accuracy_total + edge_total + 2  # +2 for consistency and performance tests
        total_passed = accuracy_passed + edge_passed + \
                      (1 if results['consistency']['passed'] else 0) + \
                      (1 if results['performance_accuracy']['accuracy_maintained'] else 0)
        
        overall_score = total_passed / total_tests
        
        print(f"\nğŸ† ç¸½é«”è©•åˆ†: {overall_score:.1%}")
        
        if overall_score >= 0.9:
            print("ğŸ‰ å„ªç§€ï¼æ‰€æœ‰æ¸¬è©¦åŸºæœ¬é€šé")
        elif overall_score >= 0.8:
            print("ğŸ‘ è‰¯å¥½ï¼å¤§éƒ¨åˆ†æ¸¬è©¦é€šé")
        elif overall_score >= 0.7:
            print("âš ï¸  ä¸€èˆ¬ï¼Œéœ€è¦ä¸€äº›æ”¹é€²")
        else:
            print("âŒ éœ€è¦é‡è¦æ”¹é€²")
        
        # ä¿å­˜çµæœï¼ˆè½‰æ›numpyé¡å‹ä»¥é¿å…JSONåºåˆ—åŒ–éŒ¯èª¤ï¼‰
        def convert_numpy_types(obj):
            """è½‰æ›numpyé¡å‹ç‚ºPythonåŸç”Ÿé¡å‹"""
            if hasattr(obj, 'item'):  # numpy scalar
                return obj.item()
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            else:
                return obj
        
        validation_report = {
            'timestamp': time.time(),
            'overall_score': float(overall_score),
            'results': convert_numpy_types(results)
        }
        
        with open('accuracy_validation_report.json', 'w', encoding='utf-8') as f:
            json.dump(validation_report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ è©³ç´°é©—è­‰å ±å‘Šå·²ä¿å­˜åˆ°: accuracy_validation_report.json")
        
    except Exception as e:
        print(f"\nâŒ æº–ç¢ºæ€§é©—è­‰å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    run_accuracy_validation()
