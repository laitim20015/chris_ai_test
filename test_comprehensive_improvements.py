#!/usr/bin/env python3
"""
å…¨é¢çš„ç©ºé–“åˆ†ææ”¹é€²æ¸¬è©¦
Comprehensive Spatial Analysis Improvements Test

é€™å€‹è…³æœ¬æ¸¬è©¦æˆ‘å€‘åœ¨Phase 1-3ä¸­å¯¦ç¾çš„æ‰€æœ‰æ”¹é€²ï¼š
1. Phase 1: åŸºç¤ç©ºé–“åˆ†ææ”¹é€²
2. Phase 2: ä½ˆå±€åˆ†æå’Œå€™é¸æ’åº
3. Phase 3: æ€§èƒ½å„ªåŒ–å’Œç·©å­˜æ©Ÿåˆ¶

é‹è¡Œé€™å€‹è…³æœ¬ä¾†é©—è­‰æ‰€æœ‰æ”¹é€²æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
"""

import sys
import os
import time
import json
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

from src.main import DocumentProcessor
from src.association.spatial_analyzer import (
    enhanced_spatial_scoring, enhanced_spatial_scoring_optimized,
    get_performance_stats, clear_cache
)
from src.association.candidate_ranker import CandidateRanker
from src.association.allen_logic import BoundingBox
from src.config.settings import get_settings

def create_test_bboxes():
    """å‰µå»ºæ¸¬è©¦ç”¨çš„é‚Šç•Œæ¡†"""
    # æ¸¬è©¦å ´æ™¯1ï¼šç†æƒ³çš„åœ–æ–‡é—œè¯ï¼ˆåœ–ç‰‡åœ¨æ–‡å­—ä¸Šæ–¹ï¼‰
    text_bbox_ideal = BoundingBox(x=100, y=300, width=300, height=50)
    image_bbox_ideal = BoundingBox(x=120, y=200, width=260, height=80)
    
    # æ¸¬è©¦å ´æ™¯2ï¼šè·é›¢è¼ƒé çš„é—œè¯ï¼ˆæ‡‰è©²å¾—åˆ†è¼ƒä½ï¼‰
    text_bbox_far = BoundingBox(x=100, y=500, width=300, height=50)
    image_bbox_far = BoundingBox(x=500, y=200, width=300, height=80)
    
    # æ¸¬è©¦å ´æ™¯3ï¼šæ°´å¹³é‡ç–Šåº¦å¾ˆå¥½çš„é—œè¯
    text_bbox_aligned = BoundingBox(x=100, y=350, width=300, height=50)
    image_bbox_aligned = BoundingBox(x=110, y=250, width=280, height=80)
    
    # æ¸¬è©¦å ´æ™¯4ï¼šæœ‰ä»‹å…¥å…ƒç´ çš„æƒ…æ³
    text_bbox_intervened = BoundingBox(x=100, y=400, width=300, height=50)
    image_bbox_intervened = BoundingBox(x=120, y=200, width=260, height=80)
    
    return [
        ("ç†æƒ³é—œè¯", text_bbox_ideal, image_bbox_ideal),
        ("è·é›¢è¼ƒé ", text_bbox_far, image_bbox_far),
        ("è‰¯å¥½å°é½Š", text_bbox_aligned, image_bbox_aligned),
        ("æœ‰ä»‹å…¥å…ƒç´ ", text_bbox_intervened, image_bbox_intervened)
    ]

def test_phase1_improvements():
    """æ¸¬è©¦Phase 1çš„åŸºç¤ç©ºé–“åˆ†ææ”¹é€²"""
    print("ğŸ” æ¸¬è©¦ Phase 1: åŸºç¤ç©ºé–“åˆ†ææ”¹é€²")
    print("=" * 50)
    
    test_cases = create_test_bboxes()
    results = []
    
    for name, text_bbox, image_bbox in test_cases:
        print(f"\næ¸¬è©¦æ¡ˆä¾‹: {name}")
        print(f"æ–‡æœ¬æ¡†: ({text_bbox.x}, {text_bbox.y}) + ({text_bbox.width}, {text_bbox.height})")
        print(f"åœ–ç‰‡æ¡†: ({image_bbox.x}, {image_bbox.y}) + ({image_bbox.width}, {image_bbox.height})")
        
        # å‰µå»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = {
            'layout_type': 'single_column',
            'all_elements': [text_bbox, image_bbox],
            'page_width': 600,
            'page_height': 800
        }
        
        # ä½¿ç”¨å¢å¼·çš„ç©ºé–“è©•åˆ†
        result = enhanced_spatial_scoring(text_bbox, image_bbox, context_info)
        
        print(f"æœ€çµ‚åˆ†æ•¸: {result['final_score']:.3f}")
        print(f"çµ„ä»¶åˆ†æ•¸:")
        for component, score in result['component_scores'].items():
            print(f"  {component}: {score:.3f}")
        
        if 'details' in result:
            print(f"è©³ç´°ä¿¡æ¯:")
            print(f"  å‚ç›´é—œä¿‚: {result['details']['relationship']}")
            print(f"  å‚ç›´é–“éš™: {result['details']['vertical_gap']:.1f}")
            print(f"  æ°´å¹³é‡ç–Š: {result['details']['horizontal_overlap']:.3f}")
        
        results.append((name, result['final_score']))
        print("-" * 30)
    
    # é©—è­‰çµæœæ˜¯å¦ç¬¦åˆé æœŸ
    scores = [score for _, score in results]
    ideal_score = scores[0]  # ç†æƒ³é—œè¯æ‡‰è©²å¾—åˆ†æœ€é«˜
    
    print(f"\nğŸ“Š Phase 1 æ¸¬è©¦çµæœç¸½çµ:")
    for name, score in results:
        print(f"  {name}: {score:.3f}")
    
    print(f"\nâœ… Phase 1 é©—è­‰:")
    print(f"  ç†æƒ³é—œè¯å¾—åˆ†: {ideal_score:.3f}")
    print(f"  æ˜¯å¦ç‚ºæœ€é«˜åˆ†: {'æ˜¯' if ideal_score == max(scores) else 'å¦'}")
    
    return results

def test_phase2_improvements():
    """æ¸¬è©¦Phase 2çš„ä½ˆå±€åˆ†æå’Œå€™é¸æ’åºæ”¹é€²"""
    print("\nğŸ—ï¸  æ¸¬è©¦ Phase 2: ä½ˆå±€åˆ†æå’Œå€™é¸æ’åº")
    print("=" * 50)
    
    # å‰µå»ºå€™é¸æ’åºå™¨
    ranker = CandidateRanker()
    
    # å‰µå»ºæ¸¬è©¦å€™é¸
    image_bbox = BoundingBox(x=200, y=200, width=200, height=100)
    
    candidates = [
        {
            'id': 'text1',
            'content': 'Figure 1: This is a test image showing the workflow process.',
            'bbox': BoundingBox(x=180, y=320, width=240, height=30),
            'type': 'text'
        },
        {
            'id': 'text2', 
            'content': 'This paragraph discusses the methodology used in our research.',
            'bbox': BoundingBox(x=50, y=350, width=250, height=50),
            'type': 'text'
        },
        {
            'id': 'text3',
            'content': 'The results shown in the diagram indicate significant improvements.',
            'bbox': BoundingBox(x=180, y=150, width=240, height=30),
            'type': 'text'
        }
    ]
    
    context_info = {
        'layout_type': 'single_column',
        'all_elements': candidates + [{'bbox': image_bbox, 'type': 'image'}],
        'page_width': 500,
        'page_height': 600
    }
    
    print("æ¸¬è©¦å€™é¸æ–‡æœ¬:")
    for i, candidate in enumerate(candidates, 1):
        print(f"  {i}. {candidate['content'][:50]}...")
    
    # åŸ·è¡Œå€™é¸æ’åº
    start_time = time.time()
    ranked_results = ranker.rank_candidates(
        text_candidates=candidates,
        image_bbox=image_bbox,
        image_content="workflow diagram",
        context_info=context_info
    )
    ranking_time = time.time() - start_time
    
    print(f"\nğŸ“ˆ å€™é¸æ’åºçµæœ (è€—æ™‚: {ranking_time:.3f}s):")
    for i, result in enumerate(ranked_results[:3], 1):
        print(f"  {i}. åˆ†æ•¸: {result.scores.final_score:.3f} - {result.text_id}")
        print(f"     Caption: {result.scores.caption_score:.3f}, ç©ºé–“: {result.scores.spatial_score:.3f}")
        print(f"     è³ªé‡: {result.scores.quality.value}, ç½®ä¿¡åº¦: {result.scores.confidence:.3f}")
    
    # æª¢æŸ¥æ˜¯å¦Captionè¢«æ­£ç¢ºè­˜åˆ¥ä¸¦æ’åœ¨å‰é¢
    best_candidate = ranked_results[0]
    has_caption = 'Figure' in candidates[0]['content']
    
    print(f"\nâœ… Phase 2 é©—è­‰:")
    print(f"  æœ€ä½³å€™é¸ID: {best_candidate.text_id}")
    print(f"  åŒ…å«Caption: {'æ˜¯' if has_caption else 'å¦'}")
    print(f"  Captionå„ªå…ˆç´š: {'æ­£ç¢º' if best_candidate.text_id == 'text1' else 'éœ€è¦èª¿æ•´'}")
    print(f"  ç¸½å€™é¸æ•¸: {len(ranked_results)}")
    
    return ranked_results

def test_phase3_performance():
    """æ¸¬è©¦Phase 3çš„æ€§èƒ½å„ªåŒ–å’Œç·©å­˜æ©Ÿåˆ¶"""
    print("\nâš¡ æ¸¬è©¦ Phase 3: æ€§èƒ½å„ªåŒ–å’Œç·©å­˜æ©Ÿåˆ¶")
    print("=" * 50)
    
    test_cases = create_test_bboxes()
    
    # æ¸…ç©ºç·©å­˜ï¼Œé–‹å§‹æ¸¬è©¦
    clear_cache()
    
    print("1. æ¸¬è©¦ç·©å­˜æ€§èƒ½")
    
    # ç¬¬ä¸€æ¬¡é‹è¡Œï¼ˆæ‡‰è©²æ˜¯ç·©å­˜æœªå‘½ä¸­ï¼‰
    print("\nç¬¬ä¸€æ¬¡é‹è¡Œï¼ˆå†·ç·©å­˜ï¼‰:")
    first_run_times = []
    
    for name, text_bbox, image_bbox in test_cases:
        context_info = {
            'layout_type': 'single_column',
            'all_elements': [text_bbox, image_bbox],
            'page_width': 600,
            'page_height': 800
        }
        
        start_time = time.time()
        result = enhanced_spatial_scoring_optimized(text_bbox, image_bbox, context_info, enable_cache=True)
        end_time = time.time()
        
        computation_time = end_time - start_time
        first_run_times.append(computation_time)
        
        print(f"  {name}: {computation_time:.4f}s, åˆ†æ•¸: {result['final_score']:.3f}, ç·©å­˜å‘½ä¸­: {result['performance']['cache_hit']}")
    
    # ç¬¬äºŒæ¬¡é‹è¡Œï¼ˆæ‡‰è©²æ˜¯ç·©å­˜å‘½ä¸­ï¼‰
    print("\nç¬¬äºŒæ¬¡é‹è¡Œï¼ˆç†±ç·©å­˜ï¼‰:")
    second_run_times = []
    
    for name, text_bbox, image_bbox in test_cases:
        context_info = {
            'layout_type': 'single_column',
            'all_elements': [text_bbox, image_bbox],
            'page_width': 600,
            'page_height': 800
        }
        
        start_time = time.time()
        result = enhanced_spatial_scoring_optimized(text_bbox, image_bbox, context_info, enable_cache=True)
        end_time = time.time()
        
        computation_time = end_time - start_time
        second_run_times.append(computation_time)
        
        print(f"  {name}: {computation_time:.4f}s, åˆ†æ•¸: {result['final_score']:.3f}, ç·©å­˜å‘½ä¸­: {result['performance']['cache_hit']}")
    
    # æ€§èƒ½çµ±è¨ˆ
    stats = get_performance_stats()
    
    print(f"\nğŸ“Š ç·©å­˜æ€§èƒ½çµ±è¨ˆ:")
    if 'overall_stats' in stats:
        overall = stats['overall_stats']
        print(f"  ç¸½è«‹æ±‚æ•¸: {overall['total_requests']}")
        print(f"  ç¸½å‘½ä¸­ç‡: {overall['overall_hit_rate']:.3f}")
        print(f"  å…§å­˜ä½¿ç”¨: {overall['total_memory_usage_mb']:.2f} MB")
    
    # è¨ˆç®—æ€§èƒ½æå‡
    avg_first_run = sum(first_run_times) / len(first_run_times)
    avg_second_run = sum(second_run_times) / len(second_run_times)
    speedup = avg_first_run / avg_second_run if avg_second_run > 0 else 1
    
    print(f"\nâš¡ æ€§èƒ½åˆ†æ:")
    print(f"  ç¬¬ä¸€æ¬¡å¹³å‡æ™‚é–“: {avg_first_run:.4f}s")
    print(f"  ç¬¬äºŒæ¬¡å¹³å‡æ™‚é–“: {avg_second_run:.4f}s")
    print(f"  åŠ é€Ÿå€æ•¸: {speedup:.1f}x")
    
    print(f"\nâœ… Phase 3 é©—è­‰:")
    print(f"  ç·©å­˜æ©Ÿåˆ¶: {'æ­£å¸¸å·¥ä½œ' if speedup > 2 else 'éœ€è¦å„ªåŒ–'}")
    print(f"  æ€§èƒ½æå‡: {'é¡¯è‘—' if speedup > 5 else 'ä¸€èˆ¬' if speedup > 2 else 'å¾®å°'}")
    
    return stats

def test_document_processing_integration():
    """æ¸¬è©¦èˆ‡ä¸»è¦æ–‡æª”è™•ç†æµç¨‹çš„é›†æˆ"""
    print("\nğŸ”— æ¸¬è©¦é›†æˆ: æ–‡æª”è™•ç†æµç¨‹")
    print("=" * 50)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ¸¬è©¦æ–‡æª”
    test_file = "Workflows-sample.pdf"
    if not Path(test_file).exists():
        print(f"âš ï¸  æ¸¬è©¦æ–‡æª” {test_file} ä¸å­˜åœ¨ï¼Œè·³éé›†æˆæ¸¬è©¦")
        return None
    
    print(f"æ­£åœ¨è™•ç†æ¸¬è©¦æ–‡æª”: {test_file}")
    
    try:
        # åˆå§‹åŒ–æ–‡æª”è™•ç†å™¨
        processor = DocumentProcessor()
        
        # è™•ç†æ–‡æª”
        start_time = time.time()
        result = processor.process_document(test_file)
        processing_time = time.time() - start_time
        
        print(f"âœ… æ–‡æª”è™•ç†å®Œæˆ (è€—æ™‚: {processing_time:.2f}s)")
        print(f"   æå–çš„åœ–ç‰‡æ•¸é‡: {len(result.get('images', []))}")
        print(f"   æå–çš„æ–‡æœ¬å¡Šæ•¸é‡: {len(result.get('text_blocks', []))}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é—œè¯åˆ†æçµæœ
        if 'associations' in result:
            associations = result['associations']
            print(f"   åœ–æ–‡é—œè¯æ•¸é‡: {len(associations)}")
            
            # é¡¯ç¤ºå‰å¹¾å€‹é—œè¯çš„åˆ†æ•¸åˆ†å¸ƒ
            if associations:
                scores = [assoc.get('final_score', 0) for assoc in associations[:5]]
                print(f"   å‰5å€‹é—œè¯åˆ†æ•¸: {[f'{s:.3f}' for s in scores]}")
        
        return result
        
    except Exception as e:
        print(f"âŒ é›†æˆæ¸¬è©¦å¤±æ•—: {e}")
        return None

def run_comprehensive_test():
    """é‹è¡Œå…¨é¢æ¸¬è©¦"""
    print("ğŸš€ é–‹å§‹å…¨é¢çš„ç©ºé–“åˆ†ææ”¹é€²æ¸¬è©¦")
    print("=" * 70)
    
    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    total_start_time = time.time()
    
    try:
        # Phase 1 æ¸¬è©¦
        phase1_results = test_phase1_improvements()
        
        # Phase 2 æ¸¬è©¦
        phase2_results = test_phase2_improvements()
        
        # Phase 3 æ¸¬è©¦
        phase3_results = test_phase3_performance()
        
        # é›†æˆæ¸¬è©¦
        integration_result = test_document_processing_integration()
        
        # ç¸½çµ
        total_time = time.time() - total_start_time
        
        print(f"\nğŸ¯ æ¸¬è©¦ç¸½çµ")
        print("=" * 70)
        print(f"ç¸½æ¸¬è©¦æ™‚é–“: {total_time:.2f}s")
        
        print(f"\nğŸ“‹ å„éšæ®µæ¸¬è©¦çµæœ:")
        print(f"  âœ… Phase 1 (åŸºç¤æ”¹é€²): å®Œæˆ")
        print(f"  âœ… Phase 2 (ä½ˆå±€åˆ†æ): å®Œæˆ") 
        print(f"  âœ… Phase 3 (æ€§èƒ½å„ªåŒ–): å®Œæˆ")
        print(f"  {'âœ…' if integration_result else 'âš ï¸ '} é›†æˆæ¸¬è©¦: {'å®Œæˆ' if integration_result else 'è·³é'}")
        
        print(f"\nğŸ‰ æ‰€æœ‰æ¸¬è©¦åŸ·è¡Œå®Œç•¢ï¼")
        
        # ä¿å­˜æ¸¬è©¦çµæœ
        test_report = {
            'timestamp': time.time(),
            'total_time': total_time,
            'phase1_results': [{'name': name, 'score': score} for name, score in phase1_results],
            'phase2_completed': phase2_results is not None,
            'phase3_stats': phase3_results,
            'integration_success': integration_result is not None
        }
        
        with open('test_report.json', 'w', encoding='utf-8') as f:
            json.dump(test_report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ æ¸¬è©¦å ±å‘Šå·²ä¿å­˜åˆ°: test_report.json")
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    run_comprehensive_test()
