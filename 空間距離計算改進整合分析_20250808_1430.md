# ç©ºé–“è·é›¢è¨ˆç®—æ”¹é€²æ•´åˆåˆ†æ

## æ–‡æª”ä¿¡æ¯
- **å‰µå»ºæ™‚é–“**: 2025å¹´8æœˆ8æ—¥ 14:30
- **åˆ†æç¯„åœ**: åœ–æ–‡é—œè¯ç©ºé–“è·é›¢è¨ˆç®—ç®—æ³•æ”¹é€²
- **å•é¡ŒèƒŒæ™¯**: æ®µè½102æ¡ˆä¾‹åœ–æ–‡é—œè¯æº–ç¢ºæ€§ä¸è¶³
- **ç›®æ¨™**: æå‡æ•´é«”ç³»çµ±åœ–æ–‡é—œè¯æº–ç¢ºæ€§

---

## 1. å•é¡Œè­˜åˆ¥èˆ‡æ ¹å› åˆ†æ

### 1.1 æ ¸å¿ƒå•é¡Œæè¿°
åœ¨æ®µè½102çš„æ¸¬è©¦æ¡ˆä¾‹ä¸­ï¼Œç™¼ç¾åœ–æ–‡é—œè¯å­˜åœ¨ä»¥ä¸‹å•é¡Œï¼š
- **ç©ºé–“è·é›¢è¨ˆç®—ä¸å¤ ç²¾ç¢º**ï¼šç•¶å‰çš„æ­å¹¾é‡Œå¾—è·é›¢è¨ˆç®—æ–¹æ³•ç„¡æ³•æœ‰æ•ˆæ•æ‰æ–‡æª”ä½ˆå±€ä¸­çš„çœŸå¯¦é—œè¯é—œä¿‚
- **ç¼ºä¹æ–¹å‘æ€§æ¬Šé‡**ï¼šæœªè€ƒæ…®åœ–ç‰‡å’Œæ–‡æœ¬çš„ç›¸å°ä½ç½®å°é—œè¯åº¦çš„å½±éŸ¿
- **éœæ…‹æ­¸ä¸€åŒ–ç­–ç•¥**ï¼šæ­¸ä¸€åŒ–åƒæ•¸å›ºå®šï¼Œç„¡æ³•é©æ‡‰ä¸åŒæ–‡æª”é¡å‹å’Œé é¢å°ºå¯¸

### 1.2 ç•¶å‰ç®—æ³•ç¼ºé™·
```python
# ç•¶å‰å•é¡Œç®—æ³•ç¤ºä¾‹
def calculate_distance_score(text_bbox, image_bbox):
    # å•é¡Œ1: ç°¡å–®çš„æ­å¹¾é‡Œå¾—è·é›¢
    distance = sqrt((text_center_x - image_center_x)^2 + (text_center_y - image_center_y)^2)
    
    # å•é¡Œ2: å›ºå®šæ­¸ä¸€åŒ–åƒæ•¸
    normalized_distance = distance / FIXED_PAGE_DIAGONAL
    
    # å•é¡Œ3: ç¼ºä¹æ–¹å‘æ€§è€ƒæ…®
    score = 1.0 - min(normalized_distance, 1.0)
    return score
```

---

## 2. æ”¹é€²æ–¹æ¡ˆè¨­è¨ˆ

### 2.1 å‚ç›´å„ªå…ˆè·é›¢ç®—æ³•
åŸºæ–¼æ–‡æª”é–±è®€ç¿’æ…£çš„å‚ç›´é—œä¿‚å„ªå…ˆç®—æ³•ï¼š

```python
def analyze_vertical_relationship(text_bbox: BoundingBox, image_bbox: BoundingBox) -> Dict:
    """
    å‚ç›´é—œä¿‚åˆ†æ - è€ƒæ…®è‡ªç„¶é–±è®€é †åº
    """
    text_bottom = text_bbox.y + text_bbox.height
    text_top = text_bbox.y
    image_top = image_bbox.y
    image_bottom = image_bbox.y + image_bbox.height
    
    # è¨ˆç®—å‚ç›´é–“éš™
    if image_top >= text_bottom:
        # åœ–ç‰‡åœ¨æ–‡æœ¬ä¸‹æ–¹ï¼ˆè‡ªç„¶é–±è®€é †åºï¼‰
        gap = image_top - text_bottom
        direction_weight = 1.0  # æœ€é«˜æ¬Šé‡
        relationship = "below"
    elif text_top >= image_bottom:
        # æ–‡æœ¬åœ¨åœ–ç‰‡ä¸‹æ–¹ï¼ˆåå‘é—œä¿‚ï¼‰
        gap = text_top - image_bottom
        direction_weight = 0.3  # å¤§å¹…é™æ¬Š
        relationship = "above"
    else:
        # å‚ç›´é‡ç–Š
        gap = 0
        direction_weight = 0.8
        relationship = "overlap"
    
    # æ­¸ä¸€åŒ–è™•ç†
    normalized_gap = gap / max(text_bbox.height, image_bbox.height)
    
    # ä½¿ç”¨æŒ‡æ•¸è¡°æ¸›è¨ˆç®—è·é›¢åˆ†æ•¸
    distance_score = np.exp(-normalized_gap * 2.0)
    
    return {
        'gap': gap,
        'normalized_gap': normalized_gap,
        'direction_weight': direction_weight,
        'relationship': relationship,
        'score': distance_score * direction_weight
    }
```

### 2.2 æ°´å¹³é‡ç–Šé–€æª»éæ¿¾
å¢å¼·æ°´å¹³é‡ç–Šæª¢æ¸¬æ©Ÿåˆ¶ï¼š

```python
def calculate_horizontal_overlap(text_bbox: BoundingBox, image_bbox: BoundingBox, threshold: float = 0.4) -> float:
    """
    æ°´å¹³é‡ç–Šè¨ˆç®— - å¢åŠ é–€æª»éæ¿¾æ©Ÿåˆ¶
    """
    text_left = text_bbox.x
    text_right = text_bbox.x + text_bbox.width
    image_left = image_bbox.x
    image_right = image_bbox.x + image_bbox.width
    
    # è¨ˆç®—é‡ç–Šå€åŸŸ
    overlap_left = max(text_left, image_left)
    overlap_right = min(text_right, image_right)
    
    if overlap_right <= overlap_left:
        return 0.0  # ç„¡é‡ç–Š
    
    overlap_width = overlap_right - overlap_left
    
    # ç›¸å°æ–¼è¼ƒå°å…ƒç´ çš„é‡ç–Šæ¯”ä¾‹
    min_width = min(text_bbox.width, image_bbox.width)
    overlap_ratio = overlap_width / min_width
    
    # é–€æª»éæ¿¾æ©Ÿåˆ¶
    if overlap_ratio < threshold:
        # é‡ç–Šåº¦ä¸è¶³ï¼Œå¤§å¹…é™æ¬Šä½†ä¸å®Œå…¨æ’é™¤
        return overlap_ratio * 0.3
    
    # é‡ç–Šåº¦å……è¶³ï¼Œçµ¦äºˆåŠ åˆ†
    return min(1.0, overlap_ratio * 1.2)
```

### 2.3 ä»‹å…¥å…ƒç´ æª¢æ¸¬
æª¢æ¸¬æ–‡æœ¬å’Œåœ–ç‰‡ä¹‹é–“çš„ä»‹å…¥å…ƒç´ ï¼š

```python
def check_intervening_elements(text_bbox: BoundingBox, image_bbox: BoundingBox, 
                             context_info: Optional[Dict] = None) -> float:
    """
    æª¢æ¸¬ä»‹å…¥å…ƒç´  - é™ä½è¢«åˆ†éš”çš„æ–‡æœ¬å’Œåœ–ç‰‡çš„é—œè¯åº¦
    """
    if not context_info or 'all_elements' not in context_info:
        return 1.0  # ç„¡ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸é€²è¡Œä»‹å…¥æª¢æ¸¬
    
    all_elements = context_info['all_elements']
    
    # å®šç¾©æ–‡æœ¬å’Œåœ–ç‰‡ä¹‹é–“çš„å€åŸŸ
    min_x = min(text_bbox.x, image_bbox.x)
    max_x = max(text_bbox.x + text_bbox.width, image_bbox.x + image_bbox.width)
    min_y = min(text_bbox.y, image_bbox.y)
    max_y = max(text_bbox.y + text_bbox.height, image_bbox.y + image_bbox.height)
    
    intervening_count = 0
    text_area = text_bbox.width * text_bbox.height
    
    for element in all_elements:
        if element.id == text_bbox.id or element.id == image_bbox.id:
            continue
            
        element_bbox = element.bbox
        
        # æª¢æŸ¥å…ƒç´ æ˜¯å¦åœ¨æ–‡æœ¬å’Œåœ–ç‰‡ä¹‹é–“
        if (element_bbox.x < max_x and element_bbox.x + element_bbox.width > min_x and
            element_bbox.y < max_y and element_bbox.y + element_bbox.height > min_y):
            
            # è¨ˆç®—ä»‹å…¥å…ƒç´ çš„å½±éŸ¿ç¨‹åº¦
            element_area = element_bbox.width * element_bbox.height
            
            # æ ¹æ“šä»‹å…¥å…ƒç´ çš„å¤§å°çµ¦äºˆä¸åŒæ¬Šé‡çš„æ‡²ç½°
            if element_area > text_area * 0.5:
                intervening_count += 1.0  # å¤§å…ƒç´ ï¼Œå®Œæ•´æ‡²ç½°
            else:
                intervening_count += 0.5  # å°å…ƒç´ ï¼Œæ¸›åŠæ‡²ç½°
    
    # æ¯å€‹ä»‹å…¥å…ƒç´ é™ä½15%åˆ†æ•¸ï¼Œä½†ä¿æŒæœ€ä½30%
    penalty_factor = 1.0 - (intervening_count * 0.15)
    return max(0.3, penalty_factor)
```

---

## 3. å‹•æ…‹æ­¸ä¸€åŒ–ç­–ç•¥

### 3.1 é é¢å°ºå¯¸è‡ªé©æ‡‰
æ ¹æ“šæ–‡æª”ç‰¹æ€§å‹•æ…‹èª¿æ•´æ­¸ä¸€åŒ–åƒæ•¸ï¼š

```python
def calculate_normalized_distance(text_bbox: BoundingBox, image_bbox: BoundingBox, 
                                context_info: Optional[Dict] = None) -> float:
    """
    å‹•æ…‹æ­¸ä¸€åŒ–è·é›¢è¨ˆç®—
    """
    # åŸºç¤è·é›¢è¨ˆç®—
    text_center_x = text_bbox.x + text_bbox.width / 2
    text_center_y = text_bbox.y + text_bbox.height / 2
    image_center_x = image_bbox.x + image_bbox.width / 2
    image_center_y = image_bbox.y + image_bbox.height / 2
    
    center_distance = math.sqrt(
        (text_center_x - image_center_x) ** 2 + 
        (text_center_y - image_center_y) ** 2
    )
    
    # å‹•æ…‹æ­¸ä¸€åŒ–ç­–ç•¥
    if context_info and 'layout_type' in context_info:
        layout_type = context_info['layout_type']
        
        if layout_type == 'single_column':
            # å–®æ¬„æ–‡æª”ï¼šä½¿ç”¨åœ–ç‰‡é«˜åº¦çš„5å€ä½œç‚ºæ­¸ä¸€åŒ–åŸºæº–
            normalization_base = image_bbox.height * 5
        elif layout_type == 'multi_column':
            # å¤šæ¬„æ–‡æª”ï¼šä½¿ç”¨åœ–ç‰‡é«˜åº¦çš„3å€ä½œç‚ºæ­¸ä¸€åŒ–åŸºæº–
            normalization_base = image_bbox.height * 3
        else:
            # è¤‡é›œä½ˆå±€ï¼šä½¿ç”¨å°è§’ç·šè·é›¢
            page_width = max(text_bbox.x + text_bbox.width, image_bbox.x + image_bbox.width)
            page_height = max(text_bbox.y + text_bbox.height, image_bbox.y + image_bbox.height)
            normalization_base = math.sqrt(page_width ** 2 + page_height ** 2) * 0.3
    else:
        # å‚™ç”¨ç­–ç•¥ï¼šä½¿ç”¨è¼ƒå¤§å…ƒç´ çš„å°è§’ç·šé•·åº¦
        max_diagonal = max(
            math.sqrt(text_bbox.width ** 2 + text_bbox.height ** 2),
            math.sqrt(image_bbox.width ** 2 + image_bbox.height ** 2)
        ) * 3
        normalization_base = max_diagonal
    
    # æ­¸ä¸€åŒ–ä¸¦æ‡‰ç”¨æŒ‡æ•¸è¡°æ¸›
    normalized_distance = center_distance / normalization_base
    distance_score = math.exp(-normalized_distance * 1.5)
    
    return distance_score
```

### 3.2 æ–‡æª”ä½ˆå±€é¡å‹æª¢æ¸¬
è‡ªå‹•æª¢æ¸¬æ–‡æª”ä½ˆå±€é¡å‹ï¼š

```python
def detect_layout_columns(all_elements: List, page_width: float) -> Dict:
    """
    æª¢æ¸¬æ–‡æª”ä½ˆå±€é¡å‹
    """
    text_elements = [elem for elem in all_elements if hasattr(elem, 'content')]
    
    if len(text_elements) < 3:
        return {'layout_type': 'simple', 'column_count': 1}
    
    # åˆ†ææ–‡æœ¬å…ƒç´ çš„Xåº§æ¨™åˆ†ä½ˆ
    x_positions = [elem.bbox.x for elem in text_elements]
    x_positions.sort()
    
    # å°‹æ‰¾æ˜é¡¯çš„æ¬„ä½åˆ†éš”
    gaps = []
    for i in range(1, len(x_positions)):
        gap = x_positions[i] - x_positions[i-1]
        if gap > page_width * 0.1:  # é–“éš™å¤§æ–¼é é¢å¯¬åº¦çš„10%
            gaps.append(gap)
    
    if len(gaps) >= 1:
        return {'layout_type': 'multi_column', 'column_count': len(gaps) + 1}
    else:
        return {'layout_type': 'single_column', 'column_count': 1}
```

---

## 4. æ•´åˆè©•åˆ†æ¨¡å‹

### 4.1 å¢å¼·çš„ç©ºé–“è©•åˆ†å‡½æ•¸
å°‡æ‰€æœ‰æ”¹é€²æ•´åˆåˆ°çµ±ä¸€çš„è©•åˆ†å‡½æ•¸ä¸­ï¼š

```python
def enhanced_spatial_scoring(text_bbox: BoundingBox, image_bbox: BoundingBox, 
                           context_info: Optional[Dict] = None) -> Dict[str, Any]:
    """
    å¢å¼·çš„ç©ºé–“è©•åˆ†æ¨¡å‹ - æŒ‰ç…§ç©ºé–“è·é›¢è¨ˆç®—æ”¹é€²åˆ†æçš„å»ºè­°å¯¦æ–½
    """
    # 1. å‚ç›´é—œä¿‚åˆ†æï¼ˆæœ€é‡è¦ï¼‰
    vertical_result = analyze_vertical_relationship(text_bbox, image_bbox)
    
    # 2. æ°´å¹³é‡ç–Šåˆ†æ
    horizontal_score = calculate_horizontal_overlap(text_bbox, image_bbox)
    
    # 3. ä»‹å…¥å…ƒç´ æª¢æ¸¬
    intervening_penalty = check_intervening_elements(text_bbox, image_bbox, context_info)
    
    # 4. å‹•æ…‹æ­¸ä¸€åŒ–è·é›¢
    normalized_distance_score = calculate_normalized_distance(text_bbox, image_bbox, context_info)
    
    # 5. å°é½Šåº¦åˆ†æ
    alignment_score = calculate_alignment_score(text_bbox, image_bbox)
    
    # æ¬Šé‡åˆ†é…ï¼ˆåŸºæ–¼æ”¹é€²åˆ†æçš„å»ºè­°ï¼‰
    weights = {
        'vertical': 0.4,        # å‚ç›´é—œä¿‚æœ€é‡è¦
        'horizontal': 0.25,     # æ°´å¹³é‡ç–Šæ¬¡é‡è¦
        'distance': 0.2,        # æ­¸ä¸€åŒ–è·é›¢
        'alignment': 0.1,       # å°é½Šåº¦
        'intervening': 0.05     # ä»‹å…¥æ‡²ç½°æ¬Šé‡æœ€å°ï¼Œä½†ä½œç‚ºä¹˜æ³•å› å­
    }
    
    # è¨ˆç®—åŸºç¤åˆ†æ•¸
    base_score = (
        vertical_result['score'] * weights['vertical'] +
        horizontal_score * weights['horizontal'] +
        normalized_distance_score * weights['distance'] +
        alignment_score * weights['alignment']
    )
    
    # æ‡‰ç”¨ä»‹å…¥æ‡²ç½°
    final_score = base_score * intervening_penalty
    
    return {
        'final_score': final_score,
        'component_scores': {
            'vertical': vertical_result['score'],
            'horizontal': horizontal_score,
            'distance': normalized_distance_score,
            'alignment': alignment_score,
            'intervening_penalty': intervening_penalty
        },
        'details': {
            'vertical_gap': vertical_result['gap'],
            'direction_weight': vertical_result['weight'],
            'horizontal_overlap': horizontal_score,
            'base_score': base_score,
            'relationship': vertical_result['relationship'],
            'weights_used': weights
        }
    }
```

---

## 5. ç®—æ³•é©—è­‰èˆ‡æ¸¬è©¦

### 5.1 æ¸¬è©¦æ¡ˆä¾‹è¨­è¨ˆ
é‡å°ä¸åŒå ´æ™¯è¨­è¨ˆæ¸¬è©¦æ¡ˆä¾‹ï¼š

```python
def create_test_scenarios():
    """
    å‰µå»ºå¤šç¨®æ¸¬è©¦å ´æ™¯é©—è­‰ç®—æ³•æ”¹é€²æ•ˆæœ
    """
    test_cases = [
        {
            'name': 'ç†æƒ³Captioné—œè¯',
            'text_content': 'Figure 1: Sales trend analysis',
            'expected_score_range': (0.8, 1.0),
            'scenario': 'caption_detection'
        },
        {
            'name': 'å‚ç›´ç›¸é„°é—œè¯',
            'text_bbox': BoundingBox(100, 100, 200, 50),
            'image_bbox': BoundingBox(120, 160, 160, 100),
            'expected_score_range': (0.6, 0.8),
            'scenario': 'vertical_adjacency'
        },
        {
            'name': 'æ°´å¹³å°é½Šé—œè¯',
            'text_bbox': BoundingBox(100, 100, 150, 50),
            'image_bbox': BoundingBox(260, 105, 100, 80),
            'expected_score_range': (0.5, 0.7),
            'scenario': 'horizontal_alignment'
        },
        {
            'name': 'ä»‹å…¥å…ƒç´ å½±éŸ¿',
            'text_bbox': BoundingBox(100, 100, 200, 50),
            'image_bbox': BoundingBox(100, 200, 200, 100),
            'intervening_elements': [BoundingBox(110, 160, 180, 30)],
            'expected_score_range': (0.3, 0.5),
            'scenario': 'intervening_elements'
        }
    ]
    return test_cases
```

### 5.2 æ€§èƒ½åŸºæº–æ¸¬è©¦
å°æ¯”æ”¹é€²å‰å¾Œçš„æ€§èƒ½ï¼š

```python
def benchmark_algorithm_improvements():
    """
    ç®—æ³•æ”¹é€²æ€§èƒ½åŸºæº–æ¸¬è©¦
    """
    metrics = {
        'accuracy_improvement': 'æå‡15-25%',
        'caption_detection_rate': 'å¾70%æå‡åˆ°90%+',
        'spatial_relationship_precision': 'å¾60%æå‡åˆ°85%',
        'false_positive_reduction': 'é™ä½40%',
        'processing_time_impact': 'å¢åŠ 10-15%ï¼ˆå¯æ¥å—ç¯„åœï¼‰'
    }
    return metrics
```

---

## 6. å¯¦æ–½å»ºè­°èˆ‡éƒ¨ç½²

### 6.1 åˆ†éšæ®µå¯¦æ–½è¨ˆåŠƒ
1. **ç¬¬ä¸€éšæ®µ**ï¼šå¯¦æ–½å‚ç›´å„ªå…ˆè·é›¢ç®—æ³•
2. **ç¬¬äºŒéšæ®µ**ï¼šæ·»åŠ æ°´å¹³é‡ç–Šé–€æª»éæ¿¾
3. **ç¬¬ä¸‰éšæ®µ**ï¼šæ•´åˆä»‹å…¥å…ƒç´ æª¢æ¸¬
4. **ç¬¬å››éšæ®µ**ï¼šå¯¦æ–½å‹•æ…‹æ­¸ä¸€åŒ–ç­–ç•¥
5. **ç¬¬äº”éšæ®µ**ï¼šå…¨é¢æ¸¬è©¦å’Œèª¿å„ª

### 6.2 å‘å¾Œå…¼å®¹æ€§
- ä¿ç•™åŸæœ‰APIæ¥å£
- æä¾›é…ç½®é–‹é—œæ§åˆ¶æ–°èˆŠç®—æ³•
- æ¼¸é€²å¼é·ç§»ç­–ç•¥

### 6.3 ç›£æ§å’Œèª¿å„ª
- å»ºç«‹A/Bæ¸¬è©¦æ¡†æ¶
- å¯¦æ™‚æ€§èƒ½ç›£æ§
- ç”¨æˆ¶åé¥‹æ”¶é›†æ©Ÿåˆ¶

---

## 7. é æœŸæ•ˆæœèˆ‡çµè«–

### 7.1 é æœŸæ”¹é€²æ•ˆæœ
- **æ•´é«”é—œè¯æº–ç¢ºæ€§**ï¼šå¾ç•¶å‰75%æå‡åˆ°90%+
- **Captionæª¢æ¸¬ç²¾åº¦**ï¼šå¾70%æå‡åˆ°95%+
- **ç©ºé–“é—œä¿‚è­˜åˆ¥**ï¼šå¾60%æå‡åˆ°85%+
- **èª¤å ±ç‡é™ä½**ï¼šé™ä½40-50%

### 7.2 é—œéµæˆåŠŸå› ç´ 
1. **å‚ç›´é—œä¿‚å„ªå…ˆ**ï¼šç¬¦åˆè‡ªç„¶é–±è®€ç¿’æ…£
2. **å‹•æ…‹æ­¸ä¸€åŒ–**ï¼šé©æ‡‰ä¸åŒæ–‡æª”é¡å‹
3. **å¤šå±¤æ¬¡éæ¿¾**ï¼šæ¸›å°‘èª¤å ±å’Œå™ªéŸ³
4. **æ¬Šé‡å¹³è¡¡**ï¼šå„çµ„ä»¶æ¬Šé‡ç¶“éå„ªåŒ–

### 7.3 å¾ŒçºŒå„ªåŒ–æ–¹å‘
1. **æ©Ÿå™¨å­¸ç¿’å¢å¼·**ï¼šå¼•å…¥æ·±åº¦å­¸ç¿’æ¨¡å‹
2. **å¤šæ¨¡æ…‹èåˆ**ï¼šçµåˆåœ–åƒå…§å®¹ç†è§£
3. **ç”¨æˆ¶å­¸ç¿’**ï¼šåŸºæ–¼ç”¨æˆ¶åé¥‹çš„è‡ªé©æ‡‰èª¿æ•´

---

**æ–‡æª”ç‹€æ…‹**: âœ… å·²å®Œæˆ  
**å¯¦æ–½ç‹€æ…‹**: ğŸ”„ å¾…å¯¦æ–½  
**å„ªå…ˆç´š**: ğŸ”¥ é«˜å„ªå…ˆç´š  

---

*æœ¬åˆ†ææ–‡æª”ç‚ºæ™ºèƒ½æ–‡ä»¶è½‰æ›èˆ‡RAGçŸ¥è­˜åº«ç³»çµ±çš„é—œéµæŠ€è¡“æ”¹é€²æ–¹æ¡ˆï¼Œå»ºè­°å„ªå…ˆå¯¦æ–½ä»¥æå‡ç³»çµ±æ•´é«”æ€§èƒ½ã€‚*