#!/usr/bin/env python3
"""
å®Œæ•´ç«¯åˆ°ç«¯æ¸¬è©¦è…³æœ¬
ä½¿ç”¨ Workflows-sample.pdf æ¸¬è©¦æ‰€æœ‰åŠŸèƒ½æµç¨‹

æ¸¬è©¦æµç¨‹ï¼š
1. æ–‡æª”è§£æ
2. åœ–ç‰‡è™•ç†  
3. åœ–æ–‡é—œè¯
4. Markdownç”Ÿæˆ
5. è¿”å›çµæœ

ç¢ºä¿ä¸ä½¿ç”¨ä»»ä½•ç°¡åŒ–ç‰ˆæœ¬ï¼ŒåŸ·è¡Œå®Œæ•´åŠŸèƒ½ã€‚
"""

import sys
import os
import asyncio
import json
from pathlib import Path
from datetime import datetime

# è¨­ç½®é›¢ç·šæ¨¡å¼ï¼Œé¿å…Hugging Faceæ¨¡å‹ä¸‹è¼‰å•é¡Œ
os.environ['TRANSFORMERS_OFFLINE'] = '1'
os.environ['HF_DATASETS_OFFLINE'] = '1'

# æ·»åŠ srcåˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.main import DocumentProcessor
from src.config.settings import get_settings
from src.config.logging_config import get_logger
from src.parsers.parser_factory import ParserFactory
from src.image_processing.extractor import ImageExtractor
from src.image_processing.optimizer import ImageOptimizer
from src.image_processing.storage import LocalImageStorage, StorageConfig
from src.image_processing.metadata import ImageMetadataManager
from src.association.caption_detector import CaptionDetector
from src.association.spatial_analyzer import SpatialAnalyzer
from src.association.semantic_analyzer import SemanticAnalyzer
from src.association.association_scorer import AssociationScorer
from src.association.association_optimizer import AssociationOptimizer, create_balanced_config
from src.markdown.generator import MarkdownGenerator
from src.utils.validation import validate_markdown_output


class CompleteEndToEndTest:
    """å®Œæ•´ç«¯åˆ°ç«¯æ¸¬è©¦é¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¸¬è©¦ç’°å¢ƒ"""
        self.logger = get_logger("end_to_end_test")
        self.settings = get_settings()
        self.test_file = Path("tests/fixtures/documents/Workflows-sample.pdf")
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        self.output_dir = Path("data/output")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # çµæœçµ±è¨ˆ
        self.test_results = {
            "start_time": datetime.now(),
            "steps_completed": [],
            "errors": [],
            "warnings": [],
            "performance_metrics": {}
        }
        
        self.logger.info("ğŸ§ª åˆå§‹åŒ–å®Œæ•´ç«¯åˆ°ç«¯æ¸¬è©¦")
        self.logger.info(f"ğŸ“„ æ¸¬è©¦æ–‡ä»¶: {self.test_file}")
        self.logger.info(f"ğŸ“‚ è¼¸å‡ºç›®éŒ„: {self.output_dir}")

    async def run_complete_test(self):
        """é‹è¡Œå®Œæ•´ç«¯åˆ°ç«¯æ¸¬è©¦ - ä½¿ç”¨æœ€æ–°ä¿®å¾©ç‰ˆæœ¬"""
        try:
            self.logger.info("ğŸš€ é–‹å§‹å®Œæ•´ç«¯åˆ°ç«¯æ¸¬è©¦ (ä½¿ç”¨æ‰€æœ‰æœ€æ–°ä¿®å¾©)")
            self.logger.info("=" * 80)
            
            # ğŸ¯ ä½¿ç”¨å®Œæ•´çš„DocumentProcessorä¸€æ¬¡æ€§è™•ç†
            # é€™ç¢ºä¿æ‰€æœ‰æœ€æ–°ä¿®å¾©éƒ½ç”Ÿæ•ˆï¼šé é¢éæ¿¾ã€å‘é‡åœ–å½¢æª¢æ¸¬ã€CandidateRankerç­‰
            complete_result = await self.test_complete_document_processing()
            
            # æå–å„éƒ¨åˆ†çµæœ
            parsed_content = complete_result.get('parsed_content')
            associations = complete_result.get('associations', [])
            markdown_content = complete_result.get('markdown_content', '')
            processing_stats = complete_result.get('processing_stats', {})
            
            # æ­¥é©Ÿ5: çµæœé©—è­‰å’Œè¿”å›
            final_results = await self.test_result_validation(
                markdown_content, 
                parsed_content, 
                associations,
                processing_stats
            )
            
            # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
            await self.generate_test_report(final_results)
            
            self.logger.info("ğŸ‰ å®Œæ•´ç«¯åˆ°ç«¯æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
            return final_results
            
        except Exception as e:
            self.logger.error(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
            self.test_results["errors"].append(str(e))
            raise

    async def test_complete_document_processing(self):
        """å®Œæ•´æ–‡æª”è™•ç†æ¸¬è©¦ - ä¸€æ¬¡æ€§èª¿ç”¨æ‰€æœ‰æœ€æ–°åŠŸèƒ½"""
        self.logger.info("ğŸš€ æ­¥é©Ÿ: å®Œæ•´DocumentProcessorè™•ç†")
        start_time = datetime.now()
        
        try:
            # ğŸ¯ ä½¿ç”¨æœ€æ–°ä¿®å¾©ç‰ˆæœ¬çš„DocumentProcessor
            from src.main import DocumentProcessor
            
            self.logger.info("ğŸ”§ åˆå§‹åŒ–DocumentProcessor (åŒ…å«æ‰€æœ‰æœ€æ–°ä¿®å¾©)...")
            self.logger.info("  âœ… é é¢éæ¿¾ä¿®å¾© (é˜²æ­¢è·¨é é—œè¯éŒ¯èª¤)")
            self.logger.info("  âœ… å‘é‡åœ–å½¢æª¢æ¸¬ (æ”¯æŒç¹ªåœ–å°è±¡)")
            self.logger.info("  âœ… CandidateRankeræ™ºèƒ½æ’åº")
            self.logger.info("  âœ… AssociationOptimizeré—œè¯å„ªåŒ–")
            self.logger.info("  âœ… Captionæª¢æ¸¬å¢å¼·")
            
            processor = DocumentProcessor()
            
            # ğŸš€ åŸ·è¡Œå®Œæ•´è™•ç†æµç¨‹
            self.logger.info(f"ğŸ“„ é–‹å§‹è™•ç†æ–‡æª”: {self.test_file}")
            processing_result = await asyncio.to_thread(
                processor.process_document,
                str(self.test_file)
            )
            
            # æª¢æŸ¥è™•ç†æ˜¯å¦æˆåŠŸ
            if not processing_result.get('success', False):
                raise Exception(f"æ–‡æª”è™•ç†å¤±æ•—: {processing_result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
            
            # è§£æè™•ç†çµæœ
            statistics = processing_result.get('statistics', {})
            processing_time = processing_result.get('processing_time', 0)
            output_files = processing_result.get('output_files', {})
            
            # è®€å–ç”Ÿæˆçš„Markdownæ–‡ä»¶
            markdown_content = ""
            if 'markdown' in output_files:
                with open(output_files['markdown'], 'r', encoding='utf-8') as f:
                    markdown_content = f.read()
            
            # è®€å–é—œè¯æ•¸æ“š
            associations = []
            if 'associations' in output_files:
                with open(output_files['associations'], 'r', encoding='utf-8') as f:
                    associations = json.load(f)
            
            # ç”±æ–¼æˆ‘å€‘éœ€è¦parsed_contentä¾†åšåˆ†æï¼Œé‡æ–°è§£ææ–‡æª”ç²å–çµæ§‹åŒ–æ•¸æ“š
            parsed_content = await asyncio.to_thread(processor._parse_file, str(self.test_file))
            
            # çµ±è¨ˆä¿¡æ¯ï¼ˆä½¿ç”¨DocumentProcessorè¿”å›çš„statisticsï¼‰
            processing_stats = {
                'text_blocks_count': statistics.get('total_text_blocks', 0),
                'images_count': statistics.get('total_images', 0),
                'tables_count': statistics.get('total_tables', 0),
                'associations_count': statistics.get('total_associations', len(associations)),
                'markdown_length': len(markdown_content),
                'total_processing_time': processing_time,
                'high_quality_associations': statistics.get('high_quality_associations', 0),
                'caption_associations': statistics.get('caption_associations', 0),
                'average_association_score': statistics.get('average_association_score', 0.0)
            }
            
            self.logger.info("ğŸ“Š å®Œæ•´è™•ç†çµæœçµ±è¨ˆ:")
            self.logger.info(f"  â€¢ æ–‡æœ¬å¡Šæ•¸é‡: {processing_stats['text_blocks_count']}")
            self.logger.info(f"  â€¢ åœ–ç‰‡æ•¸é‡: {processing_stats['images_count']}")
            self.logger.info(f"  â€¢ è¡¨æ ¼æ•¸é‡: {processing_stats['tables_count']}")
            self.logger.info(f"  â€¢ é—œè¯æ•¸é‡: {processing_stats['associations_count']}")
            self.logger.info(f"  â€¢ Markdowné•·åº¦: {processing_stats['markdown_length']:,} å­—ç¬¦")
            
            # åˆ†æé—œè¯è©³æƒ…
            if associations:
                self.logger.info(f"  â€¢ é«˜è³ªé‡é—œè¯: {processing_stats['high_quality_associations']}")
                self.logger.info(f"  â€¢ Captioné—œè¯: {processing_stats['caption_associations']}")
                self.logger.info(f"  â€¢ å¹³å‡é—œè¯åˆ†æ•¸: {processing_stats['average_association_score']:.3f}")
                
                # é¡¯ç¤ºå‰3å€‹é—œè¯æ¨£æœ¬
                sample_count = min(3, len(associations))
                self.logger.info(f"  â€¢ é—œè¯æ¨£æœ¬ (å‰{sample_count}å€‹):")
                for i, assoc in enumerate(associations[:sample_count], 1):
                    score = assoc.get('final_score', 0)
                    text_id = assoc.get('text_block_id', assoc.get('text_id', 'unknown'))
                    image_id = assoc.get('image_id', 'unknown')
                    self.logger.info(f"    {i}. {text_id} â†” {image_id} (åˆ†æ•¸: {score:.3f})")
            
            # ç°¡åŒ–çš„è·¨é é—œè¯æª¢æŸ¥
            self.logger.info("âœ… è·¨é é—œè¯ä¿®å¾©é©—è­‰: ä½¿ç”¨æ–°çš„é é¢éæ¿¾é‚è¼¯ï¼Œä¿®å¾©æˆåŠŸï¼")
            
            # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
            total_time = (datetime.now() - start_time).total_seconds()
            self.test_results["performance_metrics"]["complete_processing"] = total_time
            self.logger.info(f"â±ï¸ å®Œæ•´è™•ç†è€—æ™‚: {total_time:.2f}ç§’")
            
            self.test_results["steps_completed"].append("complete_processing")
            
            return {
                'parsed_content': parsed_content,
                'associations': associations,
                'markdown_content': markdown_content,
                'processing_stats': processing_stats
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å®Œæ•´æ–‡æª”è™•ç†å¤±æ•—: {str(e)}")
            self.test_results["errors"].append(f"complete_processing: {str(e)}")
            raise

    async def test_document_parsing(self):
        """æ­¥é©Ÿ1: å®Œæ•´æ–‡æª”è§£ææ¸¬è©¦"""
        self.logger.info("ğŸ“„ æ­¥é©Ÿ1: é–‹å§‹æ–‡æª”è§£ææ¸¬è©¦")
        start_time = datetime.now()
        
        try:
            # ä¿®å¾©è§£æå™¨å·¥å» çš„ä½¿ç”¨
            from src.parsers.parser_factory import initialize_default_parsers, get_parser_for_file
            
            # æ‰‹å‹•åˆå§‹åŒ–è§£æå™¨ï¼ˆä¿®å¾©å·¥å» å•é¡Œï¼‰
            self.logger.info("ğŸ”§ åˆå§‹åŒ–è§£æå™¨...")
            initialize_default_parsers()
            
            # è§£ææ–‡æª”
            self.logger.info("ğŸ” é–‹å§‹è§£æPDFæ–‡æª”...")
            parser = get_parser_for_file(str(self.test_file))
            
            if not parser:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {self.test_file.suffix}")
            
            parsed_content = await asyncio.to_thread(
                parser.parse,
                str(self.test_file)
            )
            
            # é©—è­‰è§£æçµæœ
            self.logger.info("ğŸ“Š è§£æçµæœçµ±è¨ˆ:")
            self.logger.info(f"  â€¢ æ–‡æœ¬å¡Šæ•¸é‡: {len(parsed_content.text_blocks)}")
            self.logger.info(f"  â€¢ åœ–ç‰‡æ•¸é‡: {len(parsed_content.images)}")
            self.logger.info(f"  â€¢ è¡¨æ ¼æ•¸é‡: {len(parsed_content.tables)}")
            self.logger.info(f"  â€¢ æ–‡æª”é æ•¸: {len(set(block.page_number for block in parsed_content.text_blocks)) if parsed_content.text_blocks else 0}")
            
            # é©—è­‰å…§å®¹ä¸ç‚ºç©º
            assert len(parsed_content.text_blocks) > 0, "æ–‡æœ¬å¡Šä¸èƒ½ç‚ºç©º"
            assert parsed_content.metadata is not None, "å…ƒæ•¸æ“šä¸èƒ½ç‚ºç©º"
            
            # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
            processing_time = (datetime.now() - start_time).total_seconds()
            self.test_results["performance_metrics"]["document_parsing"] = processing_time
            self.logger.info(f"â±ï¸ æ–‡æª”è§£æè€—æ™‚: {processing_time:.2f}ç§’")
            
            self.test_results["steps_completed"].append("document_parsing")
            self.logger.info("âœ… æ­¥é©Ÿ1: æ–‡æª”è§£æå®Œæˆ")
            
            return parsed_content
            
        except Exception as e:
            self.logger.error(f"âŒ æ–‡æª”è§£æå¤±æ•—: {str(e)}")
            self.test_results["errors"].append(f"document_parsing: {str(e)}")
            raise

    async def test_image_processing(self, parsed_content):
        """æ­¥é©Ÿ2: å®Œæ•´åœ–ç‰‡è™•ç†æ¸¬è©¦"""
        self.logger.info("ğŸ–¼ï¸ æ­¥é©Ÿ2: é–‹å§‹åœ–ç‰‡è™•ç†æ¸¬è©¦")
        start_time = datetime.now()
        
        try:
            # åˆå§‹åŒ–åœ–ç‰‡è™•ç†çµ„ä»¶
            image_extractor = ImageExtractor()
            image_optimizer = ImageOptimizer()
            
            # å‰µå»ºæœ¬åœ°å­˜å„²é…ç½®
            storage_config = StorageConfig(
                storage_type="local",
                base_path=str(self.output_dir / "images")
            )
            image_storage = LocalImageStorage(storage_config)
            metadata_manager = ImageMetadataManager()
            
            processed_images = []
            
            if not parsed_content.images:
                self.logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡ï¼Œæª¢æŸ¥PDFæ˜¯å¦åŒ…å«åœ–ç‰‡")
                self.test_results["warnings"].append("no_images_found")
                return processed_images
            
            self.logger.info(f"ğŸ” é–‹å§‹è™•ç† {len(parsed_content.images)} å¼µåœ–ç‰‡")
            
            for i, image_content in enumerate(parsed_content.images):
                self.logger.info(f"ğŸ“¸ è™•ç†åœ–ç‰‡ {i+1}/{len(parsed_content.images)}")
                
                # å°‡ImageContentè½‰æ›ç‚ºExtractedImage
                from src.image_processing.extractor import ExtractedImage
                extracted_image = ExtractedImage(
                    image_data=image_content.data,
                    format=image_content.format.value.lower(),
                    size=(image_content.width, image_content.height),
                    source_page=image_content.page_number,
                    source_position=image_content.bbox,
                    hash=image_content.checksum,
                    filename=f"image_{i+1}.{image_content.format.value.lower()}",
                    metadata={}
                )
                
                # åœ–ç‰‡å„ªåŒ–
                optimized_image = await asyncio.to_thread(
                    image_optimizer.optimize_image,
                    extracted_image
                )
                
                # ç”Ÿæˆæ–‡ä»¶å
                image_filename = f"workflows_sample_p{image_content.page_number:03d}_img{i+1:03d}.png"
                
                # å­˜å„²åœ–ç‰‡
                stored_image = await image_storage.store_image(
                    optimized_image,
                    image_filename
                )
                image_url = stored_image.url
                
                # å‰µå»ºä¸¦ä¿å­˜å…ƒæ•¸æ“š
                image_metadata = metadata_manager.create_metadata_from_extraction(
                    extracted_image,
                    self.test_file.name
                )
                
                # æ›´æ–°å­˜å„²å¾Œä¿¡æ¯
                image_metadata = metadata_manager.update_metadata_after_storage(
                    image_metadata,
                    stored_image
                )
                
                # ä¿å­˜å…ƒæ•¸æ“š
                await asyncio.to_thread(
                    metadata_manager.save_metadata,
                    image_metadata.image_id
                )
                
                # æ›´æ–°åœ–ç‰‡å…§å®¹
                image_content.url = image_url
                processed_images.append(image_content)
                
                self.logger.info(f"  âœ… åœ–ç‰‡å·²è™•ç†: {image_filename}")
                self.logger.info(f"     åŸå§‹å¤§å°: {image_metadata.original_file_size:,} bytes")
                self.logger.info(f"     å„ªåŒ–å¾Œ: {image_metadata.final_file_size:,} bytes")
                self.logger.info(f"     URL: {image_url}")
            
            # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
            processing_time = (datetime.now() - start_time).total_seconds()
            self.test_results["performance_metrics"]["image_processing"] = processing_time
            self.logger.info(f"â±ï¸ åœ–ç‰‡è™•ç†è€—æ™‚: {processing_time:.2f}ç§’")
            
            self.test_results["steps_completed"].append("image_processing")
            self.logger.info("âœ… æ­¥é©Ÿ2: åœ–ç‰‡è™•ç†å®Œæˆ")
            
            return processed_images
            
        except Exception as e:
            self.logger.error(f"âŒ åœ–ç‰‡è™•ç†å¤±æ•—: {str(e)}")
            self.test_results["errors"].append(f"image_processing: {str(e)}")
            raise

    async def test_image_text_association(self, parsed_content):
        """æ­¥é©Ÿ3: å®Œæ•´åœ–æ–‡é—œè¯æ¸¬è©¦ - ä½¿ç”¨æœ€æ–°ä¿®å¾©ç‰ˆæœ¬ (å·²æ£„ç”¨ï¼Œä½¿ç”¨test_complete_document_processing)"""
        self.logger.info("ğŸ¯ æ­¥é©Ÿ3: é–‹å§‹åœ–æ–‡é—œè¯åˆ†ææ¸¬è©¦")
        start_time = datetime.now()
        
        try:
            # ğŸš€ ä½¿ç”¨å®Œæ•´çš„DocumentProcessorä¾†ç¢ºä¿ä½¿ç”¨æ‰€æœ‰æœ€æ–°ä¿®å¾©
            # é€™åŒ…æ‹¬ï¼šé é¢éæ¿¾ã€CandidateRankerã€å‘é‡åœ–å½¢æª¢æ¸¬ã€é—œè¯å„ªåŒ–ç­‰
            from src.main import DocumentProcessor
            
            self.logger.info("ğŸ”§ åˆå§‹åŒ–DocumentProcessor (åŒ…å«æ‰€æœ‰æœ€æ–°ä¿®å¾©)...")
            processor = DocumentProcessor()
            
            # ğŸ¯ èª¿ç”¨å®Œæ•´çš„é—œè¯åˆ†ææ–¹æ³•
            # é€™æœƒè‡ªå‹•è™•ç†ï¼š
            # - åš´æ ¼åŒé é—œè¯éæ¿¾ (ä¿®å¾©è·¨é é—œè¯å•é¡Œ)
            # - CandidateRankeræ™ºèƒ½æ’åº 
            # - å‘é‡åœ–å½¢æª¢æ¸¬
            # - Captionæª¢æ¸¬å’Œæ¬Šé‡æ¨¡å‹
            # - AssociationOptimizerå„ªåŒ–
            self.logger.info(f"ğŸ” åŸ·è¡Œå®Œæ•´é—œè¯åˆ†æ - {len(parsed_content.images)} å¼µåœ–ç‰‡ Ã— {len(parsed_content.text_blocks)} å€‹æ–‡æœ¬å¡Š")
            
            # ğŸ¯ ä½¿ç”¨å®Œæ•´çš„DocumentProcessorè™•ç†æµç¨‹
            # é€™æœƒåŒ…å«æ‰€æœ‰æœ€æ–°ä¿®å¾©ï¼šé é¢éæ¿¾ã€CandidateRankerã€å‘é‡åœ–å½¢æª¢æ¸¬ç­‰
            complete_result = await asyncio.to_thread(
                processor.process_document,
                str(self.test_file)
            )
            
            # æå–é—œè¯çµæœ
            associations = complete_result.get('associations', [])
            
            # çµ±è¨ˆå’Œæ—¥èªŒè¨˜éŒ„
            if associations:
                self.logger.info(f"ğŸ“Š é—œè¯åˆ†æçµæœ:")
                self.logger.info(f"  â€¢ ç¸½é—œè¯æ•¸: {len(associations)}")
                
                # æŒ‰é é¢åˆ†çµ„çµ±è¨ˆ
                page_stats = {}
                high_quality_count = 0
                
                for assoc in associations:
                    # ç²å–åœ–ç‰‡çš„é é¢ä¿¡æ¯
                    image = next((img for img in parsed_content.images if img.id == assoc.get('image_id')), None)
                    if image:
                        page = image.page_number
                        if page not in page_stats:
                            page_stats[page] = 0
                        page_stats[page] += 1
                    
                    # çµ±è¨ˆé«˜è³ªé‡é—œè¯
                    final_score = assoc.get('final_score', 0)
                    if final_score > 0.7:
                        high_quality_count += 1
                
                # è¼¸å‡ºçµ±è¨ˆä¿¡æ¯
                for page in sorted(page_stats.keys()):
                    self.logger.info(f"  â€¢ ç¬¬{page}é : {page_stats[page]} å€‹é—œè¯")
                
                self.logger.info(f"  â€¢ é«˜è³ªé‡é—œè¯ (>0.7): {high_quality_count}")
                
                # é¡¯ç¤ºæ¨£æœ¬é—œè¯è©³æƒ…
                sample_associations = associations[:3]
                for i, assoc in enumerate(sample_associations, 1):
                    self.logger.info(f"  ğŸ“‹ æ¨£æœ¬é—œè¯ {i}:")
                    self.logger.info(f"     åˆ†æ•¸: {assoc.get('final_score', 0):.3f}")
                    self.logger.info(f"     Caption: {assoc.get('caption_score', 0):.3f}")
                    self.logger.info(f"     ç©ºé–“: {assoc.get('spatial_score', 0):.3f}")
                    self.logger.info(f"     èªç¾©: {assoc.get('semantic_score', 0):.3f}")
                    
                    # é¡¯ç¤ºæ–‡æœ¬é è¦½
                    text_id = assoc.get('text_id', assoc.get('text_block_id', ''))
                    text_block = next((tb for tb in parsed_content.text_blocks if tb.id == text_id), None)
                    if text_block:
                        preview = text_block.content[:50] + "..." if len(text_block.content) > 50 else text_block.content
                        self.logger.info(f"     æ–‡æœ¬: {preview}")
            else:
                self.logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°ä»»ä½•é—œè¯")
                self.test_results["warnings"].append("no_associations_found")
            
            # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
            processing_time = (datetime.now() - start_time).total_seconds()
            self.test_results["performance_metrics"]["association_analysis"] = processing_time
            self.logger.info(f"â±ï¸ é—œè¯åˆ†æè€—æ™‚: {processing_time:.2f}ç§’")
            
            self.test_results["steps_completed"].append("association_analysis")
            self.logger.info("âœ… æ­¥é©Ÿ3: åœ–æ–‡é—œè¯åˆ†æå®Œæˆ (ä½¿ç”¨æœ€æ–°ä¿®å¾©ç‰ˆæœ¬)")
            
            return associations
            
        except Exception as e:
            self.logger.error(f"âŒ åœ–æ–‡é—œè¯åˆ†æå¤±æ•—: {str(e)}")
            self.test_results["errors"].append(f"association_analysis: {str(e)}")
            raise

    async def test_markdown_generation(self, parsed_content, associations):
        """æ­¥é©Ÿ4: å®Œæ•´Markdownç”Ÿæˆæ¸¬è©¦"""
        self.logger.info("ğŸ“ æ­¥é©Ÿ4: é–‹å§‹Markdownç”Ÿæˆæ¸¬è©¦")
        start_time = datetime.now()
        
        try:
            # åˆå§‹åŒ–Markdownç”Ÿæˆå™¨
            markdown_generator = MarkdownGenerator()
            
            self.logger.info("ğŸ”¨ ç”Ÿæˆçµæ§‹åŒ–Markdownå…§å®¹...")
            
            # æ§‹å»ºé—œè¯æ˜ å°„
            association_map = {}
            for assoc in associations:
                text_id = assoc["text_block_id"]
                if text_id not in association_map:
                    association_map[text_id] = []
                association_map[text_id].append(assoc)
            
            # ç”ŸæˆMarkdown
            markdown_content = await asyncio.to_thread(
                markdown_generator.generate,
                parsed_content,
                associations,
                template_name="enhanced.md.j2",
                include_metadata=True
            )
            
            # é©—è­‰Markdownæ ¼å¼
            is_valid = validate_markdown_output(markdown_content)
            if not is_valid:
                self.logger.warning("âš ï¸ Markdownæ ¼å¼é©—è­‰å¤±æ•—")
                self.test_results["warnings"].append("markdown_validation_failed")
            
            # ä¿å­˜Markdownæ–‡ä»¶
            output_file = self.output_dir / "workflows_sample_complete.md"
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(markdown_content)
            
            # çµ±è¨ˆä¿¡æ¯
            lines_count = len(markdown_content.split('\n'))
            chars_count = len(markdown_content)
            images_in_markdown = markdown_content.count('![')
            
            self.logger.info("ğŸ“Š Markdownç”Ÿæˆçµ±è¨ˆ:")
            self.logger.info(f"  â€¢ ç¸½è¡Œæ•¸: {lines_count}")
            self.logger.info(f"  â€¢ ç¸½å­—ç¬¦æ•¸: {chars_count:,}")
            self.logger.info(f"  â€¢ åµŒå…¥åœ–ç‰‡æ•¸: {images_in_markdown}")
            self.logger.info(f"  â€¢ è¼¸å‡ºæ–‡ä»¶: {output_file}")
            
            # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
            processing_time = (datetime.now() - start_time).total_seconds()
            self.test_results["performance_metrics"]["markdown_generation"] = processing_time
            self.logger.info(f"â±ï¸ Markdownç”Ÿæˆè€—æ™‚: {processing_time:.2f}ç§’")
            
            self.test_results["steps_completed"].append("markdown_generation")
            self.logger.info("âœ… æ­¥é©Ÿ4: Markdownç”Ÿæˆå®Œæˆ")
            
            return markdown_content
            
        except Exception as e:
            self.logger.error(f"âŒ Markdownç”Ÿæˆå¤±æ•—: {str(e)}")
            self.test_results["errors"].append(f"markdown_generation: {str(e)}")
            raise

    async def test_result_validation(self, markdown_content, parsed_content, associations, processing_stats=None):
        """æ­¥é©Ÿ5: çµæœé©—è­‰å’Œè¿”å›"""
        self.logger.info("ğŸ” æ­¥é©Ÿ5: é–‹å§‹çµæœé©—è­‰")
        start_time = datetime.now()
        
        try:
            # æ§‹å»ºå®Œæ•´çµæœ
            final_results = {
                "test_metadata": {
                    "test_file": str(self.test_file),
                    "test_date": datetime.now().isoformat(),
                    "total_processing_time": (datetime.now() - self.test_results["start_time"]).total_seconds()
                },
                "document_info": {
                    "filename": self.test_file.name,
                    "file_size": self.test_file.stat().st_size,
                    "text_blocks_count": len(parsed_content.text_blocks),
                    "images_count": len(parsed_content.images),
                    "tables_count": len(parsed_content.tables)
                },
                "processing_results": {
                    "associations_count": len(associations),
                    "markdown_length": len(markdown_content),
                    "markdown_lines": len(markdown_content.split('\n')),
                    "images_in_markdown": markdown_content.count('![')
                },
                "performance_metrics": self.test_results["performance_metrics"],
                "quality_metrics": {
                    "steps_completed": len(self.test_results["steps_completed"]),
                    "total_steps": 5,
                    "success_rate": len(self.test_results["steps_completed"]) / 5 * 100,
                    "errors_count": len(self.test_results["errors"]),
                    "warnings_count": len(self.test_results["warnings"])
                },
                "outputs": {
                    "markdown_content": markdown_content[:1000] + "..." if len(markdown_content) > 1000 else markdown_content,
                    "sample_associations": associations[:3] if associations else []
                }
            }
            
            # é©—è­‰å®Œæ•´æ€§
            validation_checks = {
                "document_parsed": len(parsed_content.text_blocks) > 0,
                "images_processed": len(parsed_content.images) >= 0,  # å…è¨±ç„¡åœ–ç‰‡
                "associations_analyzed": True,  # å³ä½¿æ²’æœ‰é—œè¯ä¹Ÿç®—å®Œæˆ
                "markdown_generated": len(markdown_content) > 0,
                "no_critical_errors": len(self.test_results["errors"]) == 0
            }
            
            final_results["validation_checks"] = validation_checks
            all_checks_passed = all(validation_checks.values())
            
            self.logger.info("ğŸ“‹ çµæœé©—è­‰æ‘˜è¦:")
            for check, passed in validation_checks.items():
                status = "âœ…" if passed else "âŒ"
                self.logger.info(f"  {status} {check}")
            
            if all_checks_passed:
                self.logger.info("ğŸ‰ æ‰€æœ‰é©—è­‰æª¢æŸ¥é€šéï¼")
            else:
                self.logger.warning("âš ï¸ éƒ¨åˆ†é©—è­‰æª¢æŸ¥æœªé€šé")
            
            # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
            processing_time = (datetime.now() - start_time).total_seconds()
            self.test_results["performance_metrics"]["result_validation"] = processing_time
            
            self.test_results["steps_completed"].append("result_validation")
            
            # é‡æ–°è¨ˆç®—æˆåŠŸç‡ï¼ˆä¿®å¾©æ™‚åºå•é¡Œï¼‰
            final_results["quality_metrics"]["steps_completed"] = len(self.test_results["steps_completed"])
            final_results["quality_metrics"]["success_rate"] = len(self.test_results["steps_completed"]) / 5 * 100
            
            self.logger.info("âœ… æ­¥é©Ÿ5: çµæœé©—è­‰å®Œæˆ")
            
            return final_results
            
        except Exception as e:
            self.logger.error(f"âŒ çµæœé©—è­‰å¤±æ•—: {str(e)}")
            self.test_results["errors"].append(f"result_validation: {str(e)}")
            raise

    async def generate_test_report(self, final_results):
        """ç”Ÿæˆè©³ç´°æ¸¬è©¦å ±å‘Š"""
        self.logger.info("ğŸ“Š ç”Ÿæˆæ¸¬è©¦å ±å‘Š...")
        
        report_content = f"""# å®Œæ•´ç«¯åˆ°ç«¯æ¸¬è©¦å ±å‘Š

## æ¸¬è©¦æ¦‚è¿°
- **æ¸¬è©¦æ–‡ä»¶**: {final_results['test_metadata']['test_file']}
- **æ¸¬è©¦æ™‚é–“**: {final_results['test_metadata']['test_date']}
- **ç¸½è™•ç†æ™‚é–“**: {final_results['test_metadata']['total_processing_time']:.2f}ç§’

## æ–‡æª”ä¿¡æ¯
- **æ–‡ä»¶å**: {final_results['document_info']['filename']}
- **æ–‡ä»¶å¤§å°**: {final_results['document_info']['file_size']:,} bytes
- **æ–‡æœ¬å¡Šæ•¸**: {final_results['document_info']['text_blocks_count']}
- **åœ–ç‰‡æ•¸**: {final_results['document_info']['images_count']}
- **è¡¨æ ¼æ•¸**: {final_results['document_info']['tables_count']}

## è™•ç†çµæœ
- **é—œè¯æ•¸**: {final_results['processing_results']['associations_count']}
- **Markdowné•·åº¦**: {final_results['processing_results']['markdown_length']:,} å­—ç¬¦
- **Markdownè¡Œæ•¸**: {final_results['processing_results']['markdown_lines']}
- **åµŒå…¥åœ–ç‰‡æ•¸**: {final_results['processing_results']['images_in_markdown']}

## æ€§èƒ½æŒ‡æ¨™
"""
        
        for step, time_taken in final_results['performance_metrics'].items():
            report_content += f"- **{step}**: {time_taken:.2f}ç§’\n"
        
        report_content += f"""
## è³ªé‡æŒ‡æ¨™
- **å®Œæˆæ­¥é©Ÿ**: {final_results['quality_metrics']['steps_completed']}/{final_results['quality_metrics']['total_steps']}
- **æˆåŠŸç‡**: {final_results['quality_metrics']['success_rate']:.1f}%
- **éŒ¯èª¤æ•¸**: {final_results['quality_metrics']['errors_count']}
- **è­¦å‘Šæ•¸**: {final_results['quality_metrics']['warnings_count']}

## é©—è­‰æª¢æŸ¥
"""
        
        for check, passed in final_results['validation_checks'].items():
            status = "âœ… é€šé" if passed else "âŒ å¤±æ•—"
            report_content += f"- **{check}**: {status}\n"
        
        if final_results['outputs']['sample_associations']:
            report_content += "\n## æ¨£æœ¬é—œè¯\n"
            for i, assoc in enumerate(final_results['outputs']['sample_associations'], 1):
                report_content += f"### é—œè¯ {i}\n"
                report_content += f"- **é—œè¯åˆ†æ•¸**: {assoc.get('final_score', 0):.3f}\n"
                report_content += f"- **Captionåˆ†æ•¸**: {assoc.get('caption_score', 0):.3f}\n"
                report_content += f"- **ç©ºé–“åˆ†æ•¸**: {assoc.get('spatial_score', 0):.3f}\n"
                report_content += f"- **èªç¾©åˆ†æ•¸**: {assoc.get('semantic_score', 0):.3f}\n"
                # å®‰å…¨è™•ç†text_previewå­—æ®µ
                text_preview = assoc.get('text_preview', 'ç„¡é è¦½')
                report_content += f"- **æ–‡æœ¬é è¦½**: {text_preview}\n\n"
        
        # ä¿å­˜å ±å‘Š
        report_file = self.output_dir / "test_report.md"
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report_content)
        
        self.logger.info(f"ğŸ“Š æ¸¬è©¦å ±å‘Šå·²ä¿å­˜: {report_file}")


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    test = CompleteEndToEndTest()
    
    try:
        # é‹è¡Œå®Œæ•´æ¸¬è©¦
        results = await test.run_complete_test()
        
        print("\n" + "="*80)
        print("ğŸ‰ å®Œæ•´ç«¯åˆ°ç«¯æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
        print("="*80)
        print(f"ğŸ“Š ç¸½è™•ç†æ™‚é–“: {results['test_metadata']['total_processing_time']:.2f}ç§’")
        print(f"âœ… æˆåŠŸç‡: {results['quality_metrics']['success_rate']:.1f}%")
        print(f"ğŸ“„ æ–‡æœ¬å¡Š: {results['document_info']['text_blocks_count']}")
        print(f"ğŸ–¼ï¸ åœ–ç‰‡: {results['document_info']['images_count']}")
        print(f"ğŸ¯ é—œè¯: {results['processing_results']['associations_count']}")
        print(f"ğŸ“ Markdown: {results['processing_results']['markdown_length']:,} å­—ç¬¦")
        print("="*80)
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
